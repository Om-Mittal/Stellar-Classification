{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co5XVSTVGMfI"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from matplotlib.pyplot import imread\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, classification_report , accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbfqhSnZG-xQ",
        "outputId": "c94d32a1-c4f6-46d1-b7aa-8e573068c67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8noWkdkkG_r1",
        "outputId": "ea75a31d-71c3-42c4-a3e3-b7fe4be7c36d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id  ultraviolet_filter  green_filter  red_filter  \\\n",
              "0            1            17.44385      15.71196    16.14848   \n",
              "1            2            22.02806      24.01481    21.16334   \n",
              "2            3            23.07242      21.79252    20.51945   \n",
              "3            4            23.45985      23.41583    20.36645   \n",
              "4            5            23.89627      23.18005    21.12911   \n",
              "...        ...                 ...           ...         ...   \n",
              "134906  134907            19.24538      18.80673    16.41091   \n",
              "134907  134908            23.41124      22.59072    22.50731   \n",
              "134908  134909            21.76064      20.16531    20.07795   \n",
              "134909  134910            18.55473      17.70518    16.67601   \n",
              "134910  134911            22.07739      20.55631    20.97874   \n",
              "\n",
              "        near_infrared_filter       alpha      delta  redshift  stellar  \n",
              "0                  15.647619  158.167937  29.746275  0.094857        1  \n",
              "1                  20.214615  145.916931  38.083063  0.361631        1  \n",
              "2                  18.159421  245.684677  49.908866 -0.000065        2  \n",
              "3                  20.220636  204.812750  33.137303  0.643375        1  \n",
              "4                  19.818470  209.254795  55.296589  0.486448        1  \n",
              "...                      ...         ...        ...       ...      ...  \n",
              "134906             15.609013    6.218972  19.934894  0.049424        1  \n",
              "134907             22.023594  152.664791  46.368871  0.610840        3  \n",
              "134908             20.315816  358.506516  42.845364  2.133721        3  \n",
              "134909             15.922038  160.649389  18.329627  0.052593        1  \n",
              "134910             20.568744    9.907348  -1.612387 -0.000084        2  \n",
              "\n",
              "[134911 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba4ab354-51d7-41b9-bc7b-c581ac3f4c01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ultraviolet_filter</th>\n",
              "      <th>green_filter</th>\n",
              "      <th>red_filter</th>\n",
              "      <th>near_infrared_filter</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>redshift</th>\n",
              "      <th>stellar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>17.44385</td>\n",
              "      <td>15.71196</td>\n",
              "      <td>16.14848</td>\n",
              "      <td>15.647619</td>\n",
              "      <td>158.167937</td>\n",
              "      <td>29.746275</td>\n",
              "      <td>0.094857</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>22.02806</td>\n",
              "      <td>24.01481</td>\n",
              "      <td>21.16334</td>\n",
              "      <td>20.214615</td>\n",
              "      <td>145.916931</td>\n",
              "      <td>38.083063</td>\n",
              "      <td>0.361631</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>23.07242</td>\n",
              "      <td>21.79252</td>\n",
              "      <td>20.51945</td>\n",
              "      <td>18.159421</td>\n",
              "      <td>245.684677</td>\n",
              "      <td>49.908866</td>\n",
              "      <td>-0.000065</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>23.45985</td>\n",
              "      <td>23.41583</td>\n",
              "      <td>20.36645</td>\n",
              "      <td>20.220636</td>\n",
              "      <td>204.812750</td>\n",
              "      <td>33.137303</td>\n",
              "      <td>0.643375</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>23.89627</td>\n",
              "      <td>23.18005</td>\n",
              "      <td>21.12911</td>\n",
              "      <td>19.818470</td>\n",
              "      <td>209.254795</td>\n",
              "      <td>55.296589</td>\n",
              "      <td>0.486448</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134906</th>\n",
              "      <td>134907</td>\n",
              "      <td>19.24538</td>\n",
              "      <td>18.80673</td>\n",
              "      <td>16.41091</td>\n",
              "      <td>15.609013</td>\n",
              "      <td>6.218972</td>\n",
              "      <td>19.934894</td>\n",
              "      <td>0.049424</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134907</th>\n",
              "      <td>134908</td>\n",
              "      <td>23.41124</td>\n",
              "      <td>22.59072</td>\n",
              "      <td>22.50731</td>\n",
              "      <td>22.023594</td>\n",
              "      <td>152.664791</td>\n",
              "      <td>46.368871</td>\n",
              "      <td>0.610840</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134908</th>\n",
              "      <td>134909</td>\n",
              "      <td>21.76064</td>\n",
              "      <td>20.16531</td>\n",
              "      <td>20.07795</td>\n",
              "      <td>20.315816</td>\n",
              "      <td>358.506516</td>\n",
              "      <td>42.845364</td>\n",
              "      <td>2.133721</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134909</th>\n",
              "      <td>134910</td>\n",
              "      <td>18.55473</td>\n",
              "      <td>17.70518</td>\n",
              "      <td>16.67601</td>\n",
              "      <td>15.922038</td>\n",
              "      <td>160.649389</td>\n",
              "      <td>18.329627</td>\n",
              "      <td>0.052593</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134910</th>\n",
              "      <td>134911</td>\n",
              "      <td>22.07739</td>\n",
              "      <td>20.55631</td>\n",
              "      <td>20.97874</td>\n",
              "      <td>20.568744</td>\n",
              "      <td>9.907348</td>\n",
              "      <td>-1.612387</td>\n",
              "      <td>-0.000084</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>134911 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba4ab354-51d7-41b9-bc7b-c581ac3f4c01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba4ab354-51d7-41b9-bc7b-c581ac3f4c01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba4ab354-51d7-41b9-bc7b-c581ac3f4c01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f5cdedf1-1ab8-465e-b532-39d5d228f104\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5cdedf1-1ab8-465e-b532-39d5d228f104')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f5cdedf1-1ab8-465e-b532-39d5d228f104 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Loading the train dataset\n",
        "df_train = pd.read_csv('/content/gdrive/MyDrive/train_NoNTTqq.csv')\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuBnWuYoInxu"
      },
      "outputs": [],
      "source": [
        "#Dropping the id column from the train dataframe\n",
        "df_train.drop(columns='id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjxkoMktVidt"
      },
      "outputs": [],
      "source": [
        "#Replacing each value of stellar column to be in line with SparseCategoricalCrossentropy\n",
        "df_train['stellar'].replace({\n",
        "    1:0,\n",
        "    2:1,\n",
        "    3:2\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0Pqh3O2VHgRz",
        "outputId": "54e1b71d-52d4-4b0d-8229-ca4b5b5687a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  ultraviolet_filter  green_filter  red_filter  \\\n",
              "0      134912            19.63144      17.88840    16.45195   \n",
              "1      134913            25.74819      22.10760    19.97196   \n",
              "2      134914            22.38767      20.85446    20.75418   \n",
              "3      134915            22.03212      23.15455    21.86528   \n",
              "4      134916            25.01815      24.53933    22.03248   \n",
              "...       ...                 ...           ...         ...   \n",
              "89936  224848            22.41481      21.55370    19.60544   \n",
              "89937  224849            25.69069      22.74517    21.85320   \n",
              "89938  224850            20.79857      19.29775    16.87349   \n",
              "89939  224851            22.15261      20.10221    19.14552   \n",
              "89940  224852            20.59607      18.89538    18.52334   \n",
              "\n",
              "       near_infrared_filter       alpha      delta  redshift  \n",
              "0                 16.620047  336.501421   2.415351  0.000290  \n",
              "1                 19.179141  210.286161  -1.336858  0.513781  \n",
              "2                 20.073627  262.914770  46.025803  0.985297  \n",
              "3                 20.746343  146.381732  38.368224  0.712391  \n",
              "4                 22.377272  246.456081  30.515558  0.495552  \n",
              "...                     ...         ...        ...       ...  \n",
              "89936             18.617794    1.108111  30.528644  0.000479  \n",
              "89937             21.419104  155.468306  37.207024  0.649914  \n",
              "89938             16.802314  186.069454  23.731177  0.370957  \n",
              "89939             18.521452  193.814800  29.493972  0.000959  \n",
              "89940             16.551012  359.756493   5.978753  0.135022  \n",
              "\n",
              "[89941 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b7cc1d9-6054-4fcc-8423-2026b6c807ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ultraviolet_filter</th>\n",
              "      <th>green_filter</th>\n",
              "      <th>red_filter</th>\n",
              "      <th>near_infrared_filter</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>redshift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>134912</td>\n",
              "      <td>19.63144</td>\n",
              "      <td>17.88840</td>\n",
              "      <td>16.45195</td>\n",
              "      <td>16.620047</td>\n",
              "      <td>336.501421</td>\n",
              "      <td>2.415351</td>\n",
              "      <td>0.000290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>134913</td>\n",
              "      <td>25.74819</td>\n",
              "      <td>22.10760</td>\n",
              "      <td>19.97196</td>\n",
              "      <td>19.179141</td>\n",
              "      <td>210.286161</td>\n",
              "      <td>-1.336858</td>\n",
              "      <td>0.513781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>134914</td>\n",
              "      <td>22.38767</td>\n",
              "      <td>20.85446</td>\n",
              "      <td>20.75418</td>\n",
              "      <td>20.073627</td>\n",
              "      <td>262.914770</td>\n",
              "      <td>46.025803</td>\n",
              "      <td>0.985297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>134915</td>\n",
              "      <td>22.03212</td>\n",
              "      <td>23.15455</td>\n",
              "      <td>21.86528</td>\n",
              "      <td>20.746343</td>\n",
              "      <td>146.381732</td>\n",
              "      <td>38.368224</td>\n",
              "      <td>0.712391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134916</td>\n",
              "      <td>25.01815</td>\n",
              "      <td>24.53933</td>\n",
              "      <td>22.03248</td>\n",
              "      <td>22.377272</td>\n",
              "      <td>246.456081</td>\n",
              "      <td>30.515558</td>\n",
              "      <td>0.495552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89936</th>\n",
              "      <td>224848</td>\n",
              "      <td>22.41481</td>\n",
              "      <td>21.55370</td>\n",
              "      <td>19.60544</td>\n",
              "      <td>18.617794</td>\n",
              "      <td>1.108111</td>\n",
              "      <td>30.528644</td>\n",
              "      <td>0.000479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89937</th>\n",
              "      <td>224849</td>\n",
              "      <td>25.69069</td>\n",
              "      <td>22.74517</td>\n",
              "      <td>21.85320</td>\n",
              "      <td>21.419104</td>\n",
              "      <td>155.468306</td>\n",
              "      <td>37.207024</td>\n",
              "      <td>0.649914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89938</th>\n",
              "      <td>224850</td>\n",
              "      <td>20.79857</td>\n",
              "      <td>19.29775</td>\n",
              "      <td>16.87349</td>\n",
              "      <td>16.802314</td>\n",
              "      <td>186.069454</td>\n",
              "      <td>23.731177</td>\n",
              "      <td>0.370957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89939</th>\n",
              "      <td>224851</td>\n",
              "      <td>22.15261</td>\n",
              "      <td>20.10221</td>\n",
              "      <td>19.14552</td>\n",
              "      <td>18.521452</td>\n",
              "      <td>193.814800</td>\n",
              "      <td>29.493972</td>\n",
              "      <td>0.000959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89940</th>\n",
              "      <td>224852</td>\n",
              "      <td>20.59607</td>\n",
              "      <td>18.89538</td>\n",
              "      <td>18.52334</td>\n",
              "      <td>16.551012</td>\n",
              "      <td>359.756493</td>\n",
              "      <td>5.978753</td>\n",
              "      <td>0.135022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89941 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b7cc1d9-6054-4fcc-8423-2026b6c807ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b7cc1d9-6054-4fcc-8423-2026b6c807ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b7cc1d9-6054-4fcc-8423-2026b6c807ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Loading the test dataset\n",
        "df_test = pd.read_csv('/content/gdrive/MyDrive/test_SxgqOdc.csv')\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsQUviYvJ8jw"
      },
      "outputs": [],
      "source": [
        "#Storing the columns of train dataframe other than stellar in X and storing the stellar column of train dataframe in Y\n",
        "X = df_train.drop('stellar', axis='columns')\n",
        "Y = df_train.stellar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqWsm3lAK7JK"
      },
      "outputs": [],
      "source": [
        "#Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.00001)\n",
        "#To ensure maximum data is used in training, validation is minimised after optimising hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mr6eNluvM_Ll",
        "outputId": "f66fb545-7c7e-481a-e534-66a570dca98e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ultraviolet_filter  green_filter  red_filter  near_infrared_filter  \\\n",
              "0                19.63144      17.88840    16.45195             16.620047   \n",
              "1                25.74819      22.10760    19.97196             19.179141   \n",
              "2                22.38767      20.85446    20.75418             20.073627   \n",
              "3                22.03212      23.15455    21.86528             20.746343   \n",
              "4                25.01815      24.53933    22.03248             22.377272   \n",
              "...                   ...           ...         ...                   ...   \n",
              "89936            22.41481      21.55370    19.60544             18.617794   \n",
              "89937            25.69069      22.74517    21.85320             21.419104   \n",
              "89938            20.79857      19.29775    16.87349             16.802314   \n",
              "89939            22.15261      20.10221    19.14552             18.521452   \n",
              "89940            20.59607      18.89538    18.52334             16.551012   \n",
              "\n",
              "            alpha      delta  redshift  \n",
              "0      336.501421   2.415351  0.000290  \n",
              "1      210.286161  -1.336858  0.513781  \n",
              "2      262.914770  46.025803  0.985297  \n",
              "3      146.381732  38.368224  0.712391  \n",
              "4      246.456081  30.515558  0.495552  \n",
              "...           ...        ...       ...  \n",
              "89936    1.108111  30.528644  0.000479  \n",
              "89937  155.468306  37.207024  0.649914  \n",
              "89938  186.069454  23.731177  0.370957  \n",
              "89939  193.814800  29.493972  0.000959  \n",
              "89940  359.756493   5.978753  0.135022  \n",
              "\n",
              "[89941 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-549159dd-7bef-458f-9e01-a8ec046c1ddd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ultraviolet_filter</th>\n",
              "      <th>green_filter</th>\n",
              "      <th>red_filter</th>\n",
              "      <th>near_infrared_filter</th>\n",
              "      <th>alpha</th>\n",
              "      <th>delta</th>\n",
              "      <th>redshift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.63144</td>\n",
              "      <td>17.88840</td>\n",
              "      <td>16.45195</td>\n",
              "      <td>16.620047</td>\n",
              "      <td>336.501421</td>\n",
              "      <td>2.415351</td>\n",
              "      <td>0.000290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.74819</td>\n",
              "      <td>22.10760</td>\n",
              "      <td>19.97196</td>\n",
              "      <td>19.179141</td>\n",
              "      <td>210.286161</td>\n",
              "      <td>-1.336858</td>\n",
              "      <td>0.513781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.38767</td>\n",
              "      <td>20.85446</td>\n",
              "      <td>20.75418</td>\n",
              "      <td>20.073627</td>\n",
              "      <td>262.914770</td>\n",
              "      <td>46.025803</td>\n",
              "      <td>0.985297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.03212</td>\n",
              "      <td>23.15455</td>\n",
              "      <td>21.86528</td>\n",
              "      <td>20.746343</td>\n",
              "      <td>146.381732</td>\n",
              "      <td>38.368224</td>\n",
              "      <td>0.712391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25.01815</td>\n",
              "      <td>24.53933</td>\n",
              "      <td>22.03248</td>\n",
              "      <td>22.377272</td>\n",
              "      <td>246.456081</td>\n",
              "      <td>30.515558</td>\n",
              "      <td>0.495552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89936</th>\n",
              "      <td>22.41481</td>\n",
              "      <td>21.55370</td>\n",
              "      <td>19.60544</td>\n",
              "      <td>18.617794</td>\n",
              "      <td>1.108111</td>\n",
              "      <td>30.528644</td>\n",
              "      <td>0.000479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89937</th>\n",
              "      <td>25.69069</td>\n",
              "      <td>22.74517</td>\n",
              "      <td>21.85320</td>\n",
              "      <td>21.419104</td>\n",
              "      <td>155.468306</td>\n",
              "      <td>37.207024</td>\n",
              "      <td>0.649914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89938</th>\n",
              "      <td>20.79857</td>\n",
              "      <td>19.29775</td>\n",
              "      <td>16.87349</td>\n",
              "      <td>16.802314</td>\n",
              "      <td>186.069454</td>\n",
              "      <td>23.731177</td>\n",
              "      <td>0.370957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89939</th>\n",
              "      <td>22.15261</td>\n",
              "      <td>20.10221</td>\n",
              "      <td>19.14552</td>\n",
              "      <td>18.521452</td>\n",
              "      <td>193.814800</td>\n",
              "      <td>29.493972</td>\n",
              "      <td>0.000959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89940</th>\n",
              "      <td>20.59607</td>\n",
              "      <td>18.89538</td>\n",
              "      <td>18.52334</td>\n",
              "      <td>16.551012</td>\n",
              "      <td>359.756493</td>\n",
              "      <td>5.978753</td>\n",
              "      <td>0.135022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89941 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-549159dd-7bef-458f-9e01-a8ec046c1ddd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-549159dd-7bef-458f-9e01-a8ec046c1ddd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-549159dd-7bef-458f-9e01-a8ec046c1ddd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#Dropping the id colum of test dataframe\n",
        "df_test_p = df_test.drop('id', axis='columns')\n",
        "df_test_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpiBdWsIuuAg"
      },
      "outputs": [],
      "source": [
        "#Standard Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "st_x = StandardScaler()\n",
        "x_train_scaled = st_x.fit_transform(x_train)\n",
        "x_test_scaled = st_x.transform(df_test_p)\n",
        "x_val_scaled = st_x.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifiers -> We will explain"
      ],
      "metadata": {
        "id": "3UsQRb7pj7s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVMShYcTuYly",
        "outputId": "ddc02cf6-00c0-452c-9152-229b016efc91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.945004447079751"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#RandomForest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model1 = RandomForestClassifier(n_estimators=150)\n",
        "model1.fit(x_train_scaled, y_train)\n",
        "model1.score(x_val_scaled, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using RandomForest Classifier for test data\n",
        "pred_prob_test_rf = np.array(model1.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D5zqcbt_c_5",
        "outputId": "9ab48a6d-c0c3-4563-c8e4-c479556e3dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.19333333 0.80666667 0.        ]\n",
            " [0.98666667 0.01333333 0.        ]\n",
            " [0.28666667 0.01333333 0.7       ]\n",
            " ...\n",
            " [0.96666667 0.03333333 0.        ]\n",
            " [0.         1.         0.        ]\n",
            " [0.97333333 0.01333333 0.01333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LGBM Classifier\n",
        "import lightgbm as ltb\n",
        "model2 = ltb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)\n",
        "model2.fit(x_train_scaled,y_train)\n",
        "model2.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7375e3-b695-4111-eedc-9bc0b4bb8bcb",
        "id": "Sx1HwXBvHl_d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.945375037058998"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using LGBM Classifier for test data\n",
        "pred_prob_test_lgbm = np.array(model2.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_lgbm)"
      ],
      "metadata": {
        "id": "UO-yWDYJDTqq",
        "outputId": "35223647-1f08-4560-a4b1-4b3b0c2622e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.12319988 0.87381902 0.0029811 ]\n",
            " [0.99030242 0.00753548 0.0021621 ]\n",
            " [0.26947999 0.01680256 0.71371746]\n",
            " ...\n",
            " [0.97065841 0.01801679 0.0113248 ]\n",
            " [0.00633309 0.99212172 0.00154518]\n",
            " [0.99146459 0.00409811 0.0044373 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the catboost library\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "-RUmSMAzExbs",
        "outputId": "e686b7b0-a719-4db5-8a14-fc424c8bf575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1-cp37-none-manylinux1_x86_64.whl (76.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.8 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CatBoost Classifier\n",
        "import catboost as cb\n",
        "model3 = cb.CatBoostClassifier()\n",
        "model3.fit(x_train_scaled,y_train)\n",
        "model3.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "P2v_1aI8Ehlx",
        "outputId": "e4fd4c14-f088-4caa-f20a-bc3b3b27c503",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.10107\n",
            "0:\tlearn: 0.9402960\ttotal: 108ms\tremaining: 1m 47s\n",
            "1:\tlearn: 0.8222216\ttotal: 160ms\tremaining: 1m 19s\n",
            "2:\tlearn: 0.7292044\ttotal: 221ms\tremaining: 1m 13s\n",
            "3:\tlearn: 0.6554640\ttotal: 360ms\tremaining: 1m 29s\n",
            "4:\tlearn: 0.5933275\ttotal: 484ms\tremaining: 1m 36s\n",
            "5:\tlearn: 0.5417942\ttotal: 622ms\tremaining: 1m 43s\n",
            "6:\tlearn: 0.4979741\ttotal: 741ms\tremaining: 1m 45s\n",
            "7:\tlearn: 0.4615191\ttotal: 794ms\tremaining: 1m 38s\n",
            "8:\tlearn: 0.4303680\ttotal: 849ms\tremaining: 1m 33s\n",
            "9:\tlearn: 0.4029473\ttotal: 903ms\tremaining: 1m 29s\n",
            "10:\tlearn: 0.3794749\ttotal: 960ms\tremaining: 1m 26s\n",
            "11:\tlearn: 0.3595575\ttotal: 1.02s\tremaining: 1m 24s\n",
            "12:\tlearn: 0.3414552\ttotal: 1.07s\tremaining: 1m 21s\n",
            "13:\tlearn: 0.3260903\ttotal: 1.13s\tremaining: 1m 19s\n",
            "14:\tlearn: 0.3124011\ttotal: 1.19s\tremaining: 1m 18s\n",
            "15:\tlearn: 0.3007084\ttotal: 1.25s\tremaining: 1m 17s\n",
            "16:\tlearn: 0.2900462\ttotal: 1.31s\tremaining: 1m 15s\n",
            "17:\tlearn: 0.2811664\ttotal: 1.37s\tremaining: 1m 14s\n",
            "18:\tlearn: 0.2729873\ttotal: 1.43s\tremaining: 1m 13s\n",
            "19:\tlearn: 0.2659138\ttotal: 1.48s\tremaining: 1m 12s\n",
            "20:\tlearn: 0.2596938\ttotal: 1.54s\tremaining: 1m 11s\n",
            "21:\tlearn: 0.2542980\ttotal: 1.59s\tremaining: 1m 10s\n",
            "22:\tlearn: 0.2493810\ttotal: 1.65s\tremaining: 1m 10s\n",
            "23:\tlearn: 0.2453282\ttotal: 1.71s\tremaining: 1m 9s\n",
            "24:\tlearn: 0.2416404\ttotal: 1.77s\tremaining: 1m 9s\n",
            "25:\tlearn: 0.2384387\ttotal: 1.83s\tremaining: 1m 8s\n",
            "26:\tlearn: 0.2355609\ttotal: 1.89s\tremaining: 1m 8s\n",
            "27:\tlearn: 0.2329390\ttotal: 1.95s\tremaining: 1m 7s\n",
            "28:\tlearn: 0.2306582\ttotal: 2s\tremaining: 1m 7s\n",
            "29:\tlearn: 0.2287501\ttotal: 2.09s\tremaining: 1m 7s\n",
            "30:\tlearn: 0.2269636\ttotal: 2.22s\tremaining: 1m 9s\n",
            "31:\tlearn: 0.2253275\ttotal: 2.35s\tremaining: 1m 10s\n",
            "32:\tlearn: 0.2238880\ttotal: 2.44s\tremaining: 1m 11s\n",
            "33:\tlearn: 0.2225232\ttotal: 2.5s\tremaining: 1m 11s\n",
            "34:\tlearn: 0.2212816\ttotal: 2.56s\tremaining: 1m 10s\n",
            "35:\tlearn: 0.2202725\ttotal: 2.62s\tremaining: 1m 10s\n",
            "36:\tlearn: 0.2193759\ttotal: 2.68s\tremaining: 1m 9s\n",
            "37:\tlearn: 0.2185199\ttotal: 2.73s\tremaining: 1m 9s\n",
            "38:\tlearn: 0.2179054\ttotal: 2.8s\tremaining: 1m 8s\n",
            "39:\tlearn: 0.2172238\ttotal: 2.86s\tremaining: 1m 8s\n",
            "40:\tlearn: 0.2165809\ttotal: 2.92s\tremaining: 1m 8s\n",
            "41:\tlearn: 0.2160242\ttotal: 2.98s\tremaining: 1m 7s\n",
            "42:\tlearn: 0.2154203\ttotal: 3.03s\tremaining: 1m 7s\n",
            "43:\tlearn: 0.2149547\ttotal: 3.09s\tremaining: 1m 7s\n",
            "44:\tlearn: 0.2144629\ttotal: 3.15s\tremaining: 1m 6s\n",
            "45:\tlearn: 0.2138580\ttotal: 3.21s\tremaining: 1m 6s\n",
            "46:\tlearn: 0.2133559\ttotal: 3.27s\tremaining: 1m 6s\n",
            "47:\tlearn: 0.2130315\ttotal: 3.32s\tremaining: 1m 5s\n",
            "48:\tlearn: 0.2126227\ttotal: 3.38s\tremaining: 1m 5s\n",
            "49:\tlearn: 0.2122809\ttotal: 3.43s\tremaining: 1m 5s\n",
            "50:\tlearn: 0.2118567\ttotal: 3.49s\tremaining: 1m 4s\n",
            "51:\tlearn: 0.2116099\ttotal: 3.54s\tremaining: 1m 4s\n",
            "52:\tlearn: 0.2112172\ttotal: 3.6s\tremaining: 1m 4s\n",
            "53:\tlearn: 0.2109730\ttotal: 3.66s\tremaining: 1m 4s\n",
            "54:\tlearn: 0.2107188\ttotal: 3.71s\tremaining: 1m 3s\n",
            "55:\tlearn: 0.2104156\ttotal: 3.8s\tremaining: 1m 4s\n",
            "56:\tlearn: 0.2101351\ttotal: 3.86s\tremaining: 1m 3s\n",
            "57:\tlearn: 0.2098957\ttotal: 3.91s\tremaining: 1m 3s\n",
            "58:\tlearn: 0.2096648\ttotal: 3.97s\tremaining: 1m 3s\n",
            "59:\tlearn: 0.2094804\ttotal: 4.02s\tremaining: 1m 2s\n",
            "60:\tlearn: 0.2091959\ttotal: 4.09s\tremaining: 1m 2s\n",
            "61:\tlearn: 0.2089176\ttotal: 4.14s\tremaining: 1m 2s\n",
            "62:\tlearn: 0.2086564\ttotal: 4.21s\tremaining: 1m 2s\n",
            "63:\tlearn: 0.2083783\ttotal: 4.27s\tremaining: 1m 2s\n",
            "64:\tlearn: 0.2082020\ttotal: 4.33s\tremaining: 1m 2s\n",
            "65:\tlearn: 0.2079685\ttotal: 4.38s\tremaining: 1m 2s\n",
            "66:\tlearn: 0.2077553\ttotal: 4.44s\tremaining: 1m 1s\n",
            "67:\tlearn: 0.2075238\ttotal: 4.5s\tremaining: 1m 1s\n",
            "68:\tlearn: 0.2073556\ttotal: 4.55s\tremaining: 1m 1s\n",
            "69:\tlearn: 0.2071362\ttotal: 4.61s\tremaining: 1m 1s\n",
            "70:\tlearn: 0.2069859\ttotal: 4.67s\tremaining: 1m 1s\n",
            "71:\tlearn: 0.2068054\ttotal: 4.72s\tremaining: 1m\n",
            "72:\tlearn: 0.2066307\ttotal: 4.78s\tremaining: 1m\n",
            "73:\tlearn: 0.2064522\ttotal: 4.85s\tremaining: 1m\n",
            "74:\tlearn: 0.2063500\ttotal: 4.9s\tremaining: 1m\n",
            "75:\tlearn: 0.2061763\ttotal: 4.96s\tremaining: 1m\n",
            "76:\tlearn: 0.2060527\ttotal: 5.02s\tremaining: 1m\n",
            "77:\tlearn: 0.2058485\ttotal: 5.13s\tremaining: 1m\n",
            "78:\tlearn: 0.2057201\ttotal: 5.24s\tremaining: 1m 1s\n",
            "79:\tlearn: 0.2056058\ttotal: 5.37s\tremaining: 1m 1s\n",
            "80:\tlearn: 0.2055245\ttotal: 5.42s\tremaining: 1m 1s\n",
            "81:\tlearn: 0.2053793\ttotal: 5.48s\tremaining: 1m 1s\n",
            "82:\tlearn: 0.2051635\ttotal: 5.54s\tremaining: 1m 1s\n",
            "83:\tlearn: 0.2050580\ttotal: 5.6s\tremaining: 1m 1s\n",
            "84:\tlearn: 0.2049103\ttotal: 5.65s\tremaining: 1m\n",
            "85:\tlearn: 0.2046949\ttotal: 5.71s\tremaining: 1m\n",
            "86:\tlearn: 0.2046219\ttotal: 5.76s\tremaining: 1m\n",
            "87:\tlearn: 0.2045527\ttotal: 5.88s\tremaining: 1m\n",
            "88:\tlearn: 0.2044088\ttotal: 6s\tremaining: 1m 1s\n",
            "89:\tlearn: 0.2043279\ttotal: 6.17s\tremaining: 1m 2s\n",
            "90:\tlearn: 0.2042397\ttotal: 6.34s\tremaining: 1m 3s\n",
            "91:\tlearn: 0.2040969\ttotal: 6.47s\tremaining: 1m 3s\n",
            "92:\tlearn: 0.2039871\ttotal: 6.61s\tremaining: 1m 4s\n",
            "93:\tlearn: 0.2038810\ttotal: 6.78s\tremaining: 1m 5s\n",
            "94:\tlearn: 0.2037365\ttotal: 6.95s\tremaining: 1m 6s\n",
            "95:\tlearn: 0.2036093\ttotal: 7.1s\tremaining: 1m 6s\n",
            "96:\tlearn: 0.2035108\ttotal: 7.24s\tremaining: 1m 7s\n",
            "97:\tlearn: 0.2034234\ttotal: 7.43s\tremaining: 1m 8s\n",
            "98:\tlearn: 0.2033077\ttotal: 7.62s\tremaining: 1m 9s\n",
            "99:\tlearn: 0.2032309\ttotal: 7.74s\tremaining: 1m 9s\n",
            "100:\tlearn: 0.2030725\ttotal: 7.79s\tremaining: 1m 9s\n",
            "101:\tlearn: 0.2029700\ttotal: 7.86s\tremaining: 1m 9s\n",
            "102:\tlearn: 0.2028351\ttotal: 7.92s\tremaining: 1m 8s\n",
            "103:\tlearn: 0.2027346\ttotal: 8.07s\tremaining: 1m 9s\n",
            "104:\tlearn: 0.2026372\ttotal: 8.16s\tremaining: 1m 9s\n",
            "105:\tlearn: 0.2025595\ttotal: 8.22s\tremaining: 1m 9s\n",
            "106:\tlearn: 0.2024935\ttotal: 8.27s\tremaining: 1m 9s\n",
            "107:\tlearn: 0.2023839\ttotal: 8.34s\tremaining: 1m 8s\n",
            "108:\tlearn: 0.2022852\ttotal: 8.46s\tremaining: 1m 9s\n",
            "109:\tlearn: 0.2022084\ttotal: 8.57s\tremaining: 1m 9s\n",
            "110:\tlearn: 0.2021041\ttotal: 8.63s\tremaining: 1m 9s\n",
            "111:\tlearn: 0.2020609\ttotal: 8.71s\tremaining: 1m 9s\n",
            "112:\tlearn: 0.2020085\ttotal: 8.82s\tremaining: 1m 9s\n",
            "113:\tlearn: 0.2018912\ttotal: 8.96s\tremaining: 1m 9s\n",
            "114:\tlearn: 0.2017657\ttotal: 9.1s\tremaining: 1m 10s\n",
            "115:\tlearn: 0.2016587\ttotal: 9.23s\tremaining: 1m 10s\n",
            "116:\tlearn: 0.2016001\ttotal: 9.38s\tremaining: 1m 10s\n",
            "117:\tlearn: 0.2014822\ttotal: 9.48s\tremaining: 1m 10s\n",
            "118:\tlearn: 0.2014294\ttotal: 9.54s\tremaining: 1m 10s\n",
            "119:\tlearn: 0.2013838\ttotal: 9.64s\tremaining: 1m 10s\n",
            "120:\tlearn: 0.2013214\ttotal: 9.76s\tremaining: 1m 10s\n",
            "121:\tlearn: 0.2012678\ttotal: 9.88s\tremaining: 1m 11s\n",
            "122:\tlearn: 0.2011878\ttotal: 10s\tremaining: 1m 11s\n",
            "123:\tlearn: 0.2011317\ttotal: 10.1s\tremaining: 1m 11s\n",
            "124:\tlearn: 0.2011001\ttotal: 10.2s\tremaining: 1m 11s\n",
            "125:\tlearn: 0.2010051\ttotal: 10.3s\tremaining: 1m 11s\n",
            "126:\tlearn: 0.2009059\ttotal: 10.5s\tremaining: 1m 12s\n",
            "127:\tlearn: 0.2008591\ttotal: 10.6s\tremaining: 1m 12s\n",
            "128:\tlearn: 0.2008274\ttotal: 10.7s\tremaining: 1m 12s\n",
            "129:\tlearn: 0.2007473\ttotal: 10.9s\tremaining: 1m 12s\n",
            "130:\tlearn: 0.2006841\ttotal: 11s\tremaining: 1m 12s\n",
            "131:\tlearn: 0.2005999\ttotal: 11.1s\tremaining: 1m 13s\n",
            "132:\tlearn: 0.2005196\ttotal: 11.3s\tremaining: 1m 13s\n",
            "133:\tlearn: 0.2004560\ttotal: 11.4s\tremaining: 1m 13s\n",
            "134:\tlearn: 0.2003555\ttotal: 11.6s\tremaining: 1m 14s\n",
            "135:\tlearn: 0.2002815\ttotal: 11.7s\tremaining: 1m 14s\n",
            "136:\tlearn: 0.2002350\ttotal: 11.8s\tremaining: 1m 14s\n",
            "137:\tlearn: 0.2001596\ttotal: 11.9s\tremaining: 1m 14s\n",
            "138:\tlearn: 0.2001121\ttotal: 12s\tremaining: 1m 14s\n",
            "139:\tlearn: 0.2000437\ttotal: 12.2s\tremaining: 1m 14s\n",
            "140:\tlearn: 0.1999073\ttotal: 12.3s\tremaining: 1m 15s\n",
            "141:\tlearn: 0.1998047\ttotal: 12.4s\tremaining: 1m 15s\n",
            "142:\tlearn: 0.1997092\ttotal: 12.5s\tremaining: 1m 14s\n",
            "143:\tlearn: 0.1996320\ttotal: 12.6s\tremaining: 1m 14s\n",
            "144:\tlearn: 0.1995599\ttotal: 12.7s\tremaining: 1m 14s\n",
            "145:\tlearn: 0.1994970\ttotal: 12.8s\tremaining: 1m 14s\n",
            "146:\tlearn: 0.1993996\ttotal: 12.9s\tremaining: 1m 15s\n",
            "147:\tlearn: 0.1993464\ttotal: 13.1s\tremaining: 1m 15s\n",
            "148:\tlearn: 0.1992822\ttotal: 13.2s\tremaining: 1m 15s\n",
            "149:\tlearn: 0.1991931\ttotal: 13.2s\tremaining: 1m 14s\n",
            "150:\tlearn: 0.1990956\ttotal: 13.3s\tremaining: 1m 14s\n",
            "151:\tlearn: 0.1990545\ttotal: 13.3s\tremaining: 1m 14s\n",
            "152:\tlearn: 0.1989908\ttotal: 13.4s\tremaining: 1m 14s\n",
            "153:\tlearn: 0.1988988\ttotal: 13.5s\tremaining: 1m 13s\n",
            "154:\tlearn: 0.1988598\ttotal: 13.5s\tremaining: 1m 13s\n",
            "155:\tlearn: 0.1988192\ttotal: 13.6s\tremaining: 1m 13s\n",
            "156:\tlearn: 0.1987804\ttotal: 13.6s\tremaining: 1m 13s\n",
            "157:\tlearn: 0.1986732\ttotal: 13.7s\tremaining: 1m 12s\n",
            "158:\tlearn: 0.1986108\ttotal: 13.8s\tremaining: 1m 12s\n",
            "159:\tlearn: 0.1985641\ttotal: 14s\tremaining: 1m 13s\n",
            "160:\tlearn: 0.1985109\ttotal: 14.1s\tremaining: 1m 13s\n",
            "161:\tlearn: 0.1984692\ttotal: 14.2s\tremaining: 1m 13s\n",
            "162:\tlearn: 0.1984145\ttotal: 14.4s\tremaining: 1m 13s\n",
            "163:\tlearn: 0.1983662\ttotal: 14.5s\tremaining: 1m 13s\n",
            "164:\tlearn: 0.1983136\ttotal: 14.6s\tremaining: 1m 13s\n",
            "165:\tlearn: 0.1982053\ttotal: 14.7s\tremaining: 1m 13s\n",
            "166:\tlearn: 0.1981272\ttotal: 14.8s\tremaining: 1m 13s\n",
            "167:\tlearn: 0.1980844\ttotal: 15s\tremaining: 1m 14s\n",
            "168:\tlearn: 0.1979722\ttotal: 15.1s\tremaining: 1m 14s\n",
            "169:\tlearn: 0.1979149\ttotal: 15.1s\tremaining: 1m 13s\n",
            "170:\tlearn: 0.1978781\ttotal: 15.2s\tremaining: 1m 13s\n",
            "171:\tlearn: 0.1977952\ttotal: 15.3s\tremaining: 1m 13s\n",
            "172:\tlearn: 0.1977351\ttotal: 15.4s\tremaining: 1m 13s\n",
            "173:\tlearn: 0.1976751\ttotal: 15.4s\tremaining: 1m 13s\n",
            "174:\tlearn: 0.1976420\ttotal: 15.5s\tremaining: 1m 12s\n",
            "175:\tlearn: 0.1976071\ttotal: 15.6s\tremaining: 1m 13s\n",
            "176:\tlearn: 0.1975187\ttotal: 15.7s\tremaining: 1m 13s\n",
            "177:\tlearn: 0.1974724\ttotal: 15.9s\tremaining: 1m 13s\n",
            "178:\tlearn: 0.1974377\ttotal: 15.9s\tremaining: 1m 12s\n",
            "179:\tlearn: 0.1973872\ttotal: 16s\tremaining: 1m 12s\n",
            "180:\tlearn: 0.1973353\ttotal: 16s\tremaining: 1m 12s\n",
            "181:\tlearn: 0.1973015\ttotal: 16.1s\tremaining: 1m 12s\n",
            "182:\tlearn: 0.1972478\ttotal: 16.2s\tremaining: 1m 12s\n",
            "183:\tlearn: 0.1972094\ttotal: 16.3s\tremaining: 1m 12s\n",
            "184:\tlearn: 0.1971689\ttotal: 16.4s\tremaining: 1m 12s\n",
            "185:\tlearn: 0.1971353\ttotal: 16.4s\tremaining: 1m 11s\n",
            "186:\tlearn: 0.1970854\ttotal: 16.5s\tremaining: 1m 11s\n",
            "187:\tlearn: 0.1970209\ttotal: 16.6s\tremaining: 1m 11s\n",
            "188:\tlearn: 0.1969852\ttotal: 16.6s\tremaining: 1m 11s\n",
            "189:\tlearn: 0.1969118\ttotal: 16.7s\tremaining: 1m 11s\n",
            "190:\tlearn: 0.1968519\ttotal: 16.7s\tremaining: 1m 10s\n",
            "191:\tlearn: 0.1967900\ttotal: 16.8s\tremaining: 1m 10s\n",
            "192:\tlearn: 0.1967429\ttotal: 16.9s\tremaining: 1m 10s\n",
            "193:\tlearn: 0.1966912\ttotal: 17s\tremaining: 1m 10s\n",
            "194:\tlearn: 0.1966723\ttotal: 17.1s\tremaining: 1m 10s\n",
            "195:\tlearn: 0.1965965\ttotal: 17.3s\tremaining: 1m 10s\n",
            "196:\tlearn: 0.1965692\ttotal: 17.4s\tremaining: 1m 11s\n",
            "197:\tlearn: 0.1965096\ttotal: 17.5s\tremaining: 1m 11s\n",
            "198:\tlearn: 0.1964562\ttotal: 17.7s\tremaining: 1m 11s\n",
            "199:\tlearn: 0.1963792\ttotal: 17.8s\tremaining: 1m 11s\n",
            "200:\tlearn: 0.1963633\ttotal: 17.9s\tremaining: 1m 11s\n",
            "201:\tlearn: 0.1963143\ttotal: 18.1s\tremaining: 1m 11s\n",
            "202:\tlearn: 0.1962706\ttotal: 18.2s\tremaining: 1m 11s\n",
            "203:\tlearn: 0.1962388\ttotal: 18.3s\tremaining: 1m 11s\n",
            "204:\tlearn: 0.1962056\ttotal: 18.4s\tremaining: 1m 11s\n",
            "205:\tlearn: 0.1961693\ttotal: 18.6s\tremaining: 1m 11s\n",
            "206:\tlearn: 0.1961463\ttotal: 18.7s\tremaining: 1m 11s\n",
            "207:\tlearn: 0.1961235\ttotal: 18.8s\tremaining: 1m 11s\n",
            "208:\tlearn: 0.1960806\ttotal: 18.9s\tremaining: 1m 11s\n",
            "209:\tlearn: 0.1960086\ttotal: 19.1s\tremaining: 1m 11s\n",
            "210:\tlearn: 0.1959277\ttotal: 19.2s\tremaining: 1m 11s\n",
            "211:\tlearn: 0.1958793\ttotal: 19.3s\tremaining: 1m 11s\n",
            "212:\tlearn: 0.1958399\ttotal: 19.5s\tremaining: 1m 11s\n",
            "213:\tlearn: 0.1957889\ttotal: 19.5s\tremaining: 1m 11s\n",
            "214:\tlearn: 0.1957231\ttotal: 19.6s\tremaining: 1m 11s\n",
            "215:\tlearn: 0.1956702\ttotal: 19.7s\tremaining: 1m 11s\n",
            "216:\tlearn: 0.1956101\ttotal: 19.8s\tremaining: 1m 11s\n",
            "217:\tlearn: 0.1955510\ttotal: 19.9s\tremaining: 1m 11s\n",
            "218:\tlearn: 0.1954923\ttotal: 20.1s\tremaining: 1m 11s\n",
            "219:\tlearn: 0.1954518\ttotal: 20.2s\tremaining: 1m 11s\n",
            "220:\tlearn: 0.1953913\ttotal: 20.3s\tremaining: 1m 11s\n",
            "221:\tlearn: 0.1953194\ttotal: 20.4s\tremaining: 1m 11s\n",
            "222:\tlearn: 0.1952890\ttotal: 20.4s\tremaining: 1m 11s\n",
            "223:\tlearn: 0.1952656\ttotal: 20.5s\tremaining: 1m 10s\n",
            "224:\tlearn: 0.1952446\ttotal: 20.6s\tremaining: 1m 10s\n",
            "225:\tlearn: 0.1951701\ttotal: 20.7s\tremaining: 1m 10s\n",
            "226:\tlearn: 0.1951489\ttotal: 20.8s\tremaining: 1m 10s\n",
            "227:\tlearn: 0.1950919\ttotal: 20.9s\tremaining: 1m 10s\n",
            "228:\tlearn: 0.1950278\ttotal: 21s\tremaining: 1m 10s\n",
            "229:\tlearn: 0.1949662\ttotal: 21.1s\tremaining: 1m 10s\n",
            "230:\tlearn: 0.1949243\ttotal: 21.3s\tremaining: 1m 10s\n",
            "231:\tlearn: 0.1948835\ttotal: 21.4s\tremaining: 1m 10s\n",
            "232:\tlearn: 0.1948162\ttotal: 21.5s\tremaining: 1m 10s\n",
            "233:\tlearn: 0.1947907\ttotal: 21.6s\tremaining: 1m 10s\n",
            "234:\tlearn: 0.1947501\ttotal: 21.6s\tremaining: 1m 10s\n",
            "235:\tlearn: 0.1947149\ttotal: 21.7s\tremaining: 1m 10s\n",
            "236:\tlearn: 0.1946583\ttotal: 21.7s\tremaining: 1m 9s\n",
            "237:\tlearn: 0.1945578\ttotal: 21.8s\tremaining: 1m 9s\n",
            "238:\tlearn: 0.1945320\ttotal: 22s\tremaining: 1m 9s\n",
            "239:\tlearn: 0.1945112\ttotal: 22s\tremaining: 1m 9s\n",
            "240:\tlearn: 0.1944634\ttotal: 22.1s\tremaining: 1m 9s\n",
            "241:\tlearn: 0.1944159\ttotal: 22.2s\tremaining: 1m 9s\n",
            "242:\tlearn: 0.1943797\ttotal: 22.3s\tremaining: 1m 9s\n",
            "243:\tlearn: 0.1943347\ttotal: 22.4s\tremaining: 1m 9s\n",
            "244:\tlearn: 0.1943065\ttotal: 22.4s\tremaining: 1m 9s\n",
            "245:\tlearn: 0.1942774\ttotal: 22.5s\tremaining: 1m 8s\n",
            "246:\tlearn: 0.1942108\ttotal: 22.5s\tremaining: 1m 8s\n",
            "247:\tlearn: 0.1941382\ttotal: 22.7s\tremaining: 1m 8s\n",
            "248:\tlearn: 0.1940768\ttotal: 22.8s\tremaining: 1m 8s\n",
            "249:\tlearn: 0.1940292\ttotal: 22.9s\tremaining: 1m 8s\n",
            "250:\tlearn: 0.1940048\ttotal: 22.9s\tremaining: 1m 8s\n",
            "251:\tlearn: 0.1939628\ttotal: 23s\tremaining: 1m 8s\n",
            "252:\tlearn: 0.1939105\ttotal: 23s\tremaining: 1m 8s\n",
            "253:\tlearn: 0.1938749\ttotal: 23.2s\tremaining: 1m 8s\n",
            "254:\tlearn: 0.1938358\ttotal: 23.2s\tremaining: 1m 7s\n",
            "255:\tlearn: 0.1937444\ttotal: 23.3s\tremaining: 1m 7s\n",
            "256:\tlearn: 0.1937190\ttotal: 23.3s\tremaining: 1m 7s\n",
            "257:\tlearn: 0.1936599\ttotal: 23.4s\tremaining: 1m 7s\n",
            "258:\tlearn: 0.1936011\ttotal: 23.5s\tremaining: 1m 7s\n",
            "259:\tlearn: 0.1935484\ttotal: 23.6s\tremaining: 1m 7s\n",
            "260:\tlearn: 0.1935147\ttotal: 23.6s\tremaining: 1m 6s\n",
            "261:\tlearn: 0.1934649\ttotal: 23.7s\tremaining: 1m 6s\n",
            "262:\tlearn: 0.1934329\ttotal: 23.8s\tremaining: 1m 6s\n",
            "263:\tlearn: 0.1934171\ttotal: 23.9s\tremaining: 1m 6s\n",
            "264:\tlearn: 0.1933868\ttotal: 24s\tremaining: 1m 6s\n",
            "265:\tlearn: 0.1933462\ttotal: 24.1s\tremaining: 1m 6s\n",
            "266:\tlearn: 0.1933073\ttotal: 24.2s\tremaining: 1m 6s\n",
            "267:\tlearn: 0.1932631\ttotal: 24.2s\tremaining: 1m 6s\n",
            "268:\tlearn: 0.1932142\ttotal: 24.4s\tremaining: 1m 6s\n",
            "269:\tlearn: 0.1931762\ttotal: 24.4s\tremaining: 1m 6s\n",
            "270:\tlearn: 0.1931256\ttotal: 24.5s\tremaining: 1m 5s\n",
            "271:\tlearn: 0.1930733\ttotal: 24.5s\tremaining: 1m 5s\n",
            "272:\tlearn: 0.1930392\ttotal: 24.6s\tremaining: 1m 5s\n",
            "273:\tlearn: 0.1929987\ttotal: 24.7s\tremaining: 1m 5s\n",
            "274:\tlearn: 0.1929853\ttotal: 24.8s\tremaining: 1m 5s\n",
            "275:\tlearn: 0.1929025\ttotal: 24.8s\tremaining: 1m 5s\n",
            "276:\tlearn: 0.1928571\ttotal: 24.9s\tremaining: 1m 4s\n",
            "277:\tlearn: 0.1928077\ttotal: 24.9s\tremaining: 1m 4s\n",
            "278:\tlearn: 0.1927720\ttotal: 25s\tremaining: 1m 4s\n",
            "279:\tlearn: 0.1927174\ttotal: 25.2s\tremaining: 1m 4s\n",
            "280:\tlearn: 0.1926967\ttotal: 25.3s\tremaining: 1m 4s\n",
            "281:\tlearn: 0.1926450\ttotal: 25.4s\tremaining: 1m 4s\n",
            "282:\tlearn: 0.1926051\ttotal: 25.4s\tremaining: 1m 4s\n",
            "283:\tlearn: 0.1925831\ttotal: 25.5s\tremaining: 1m 4s\n",
            "284:\tlearn: 0.1925293\ttotal: 25.6s\tremaining: 1m 4s\n",
            "285:\tlearn: 0.1924819\ttotal: 25.7s\tremaining: 1m 4s\n",
            "286:\tlearn: 0.1924443\ttotal: 25.8s\tremaining: 1m 4s\n",
            "287:\tlearn: 0.1924266\ttotal: 25.9s\tremaining: 1m 3s\n",
            "288:\tlearn: 0.1923674\ttotal: 25.9s\tremaining: 1m 3s\n",
            "289:\tlearn: 0.1923442\ttotal: 26s\tremaining: 1m 3s\n",
            "290:\tlearn: 0.1923221\ttotal: 26.1s\tremaining: 1m 3s\n",
            "291:\tlearn: 0.1922872\ttotal: 26.2s\tremaining: 1m 3s\n",
            "292:\tlearn: 0.1922541\ttotal: 26.3s\tremaining: 1m 3s\n",
            "293:\tlearn: 0.1922329\ttotal: 26.4s\tremaining: 1m 3s\n",
            "294:\tlearn: 0.1921986\ttotal: 26.4s\tremaining: 1m 3s\n",
            "295:\tlearn: 0.1921767\ttotal: 26.5s\tremaining: 1m 2s\n",
            "296:\tlearn: 0.1921567\ttotal: 26.6s\tremaining: 1m 2s\n",
            "297:\tlearn: 0.1921345\ttotal: 26.7s\tremaining: 1m 2s\n",
            "298:\tlearn: 0.1921090\ttotal: 26.8s\tremaining: 1m 2s\n",
            "299:\tlearn: 0.1920882\ttotal: 26.9s\tremaining: 1m 2s\n",
            "300:\tlearn: 0.1920658\ttotal: 27s\tremaining: 1m 2s\n",
            "301:\tlearn: 0.1920243\ttotal: 27.1s\tremaining: 1m 2s\n",
            "302:\tlearn: 0.1919923\ttotal: 27.2s\tremaining: 1m 2s\n",
            "303:\tlearn: 0.1919408\ttotal: 27.2s\tremaining: 1m 2s\n",
            "304:\tlearn: 0.1918943\ttotal: 27.4s\tremaining: 1m 2s\n",
            "305:\tlearn: 0.1918708\ttotal: 27.5s\tremaining: 1m 2s\n",
            "306:\tlearn: 0.1918251\ttotal: 27.5s\tremaining: 1m 2s\n",
            "307:\tlearn: 0.1917935\ttotal: 27.6s\tremaining: 1m 1s\n",
            "308:\tlearn: 0.1917713\ttotal: 27.6s\tremaining: 1m 1s\n",
            "309:\tlearn: 0.1917439\ttotal: 27.7s\tremaining: 1m 1s\n",
            "310:\tlearn: 0.1917207\ttotal: 27.8s\tremaining: 1m 1s\n",
            "311:\tlearn: 0.1916996\ttotal: 27.9s\tremaining: 1m 1s\n",
            "312:\tlearn: 0.1916578\ttotal: 27.9s\tremaining: 1m 1s\n",
            "313:\tlearn: 0.1916322\ttotal: 28s\tremaining: 1m 1s\n",
            "314:\tlearn: 0.1916169\ttotal: 28.1s\tremaining: 1m 1s\n",
            "315:\tlearn: 0.1915655\ttotal: 28.3s\tremaining: 1m 1s\n",
            "316:\tlearn: 0.1915276\ttotal: 28.3s\tremaining: 1m 1s\n",
            "317:\tlearn: 0.1914981\ttotal: 28.4s\tremaining: 1m\n",
            "318:\tlearn: 0.1914631\ttotal: 28.5s\tremaining: 1m\n",
            "319:\tlearn: 0.1914305\ttotal: 28.6s\tremaining: 1m\n",
            "320:\tlearn: 0.1913828\ttotal: 28.7s\tremaining: 1m\n",
            "321:\tlearn: 0.1913513\ttotal: 28.7s\tremaining: 1m\n",
            "322:\tlearn: 0.1913248\ttotal: 28.8s\tremaining: 1m\n",
            "323:\tlearn: 0.1912853\ttotal: 28.8s\tremaining: 1m\n",
            "324:\tlearn: 0.1912556\ttotal: 28.9s\tremaining: 1m\n",
            "325:\tlearn: 0.1912237\ttotal: 29s\tremaining: 60s\n",
            "326:\tlearn: 0.1911980\ttotal: 29.1s\tremaining: 59.8s\n",
            "327:\tlearn: 0.1911660\ttotal: 29.1s\tremaining: 59.6s\n",
            "328:\tlearn: 0.1911475\ttotal: 29.2s\tremaining: 59.5s\n",
            "329:\tlearn: 0.1911248\ttotal: 29.3s\tremaining: 59.4s\n",
            "330:\tlearn: 0.1910939\ttotal: 29.4s\tremaining: 59.4s\n",
            "331:\tlearn: 0.1910684\ttotal: 29.5s\tremaining: 59.3s\n",
            "332:\tlearn: 0.1910260\ttotal: 29.5s\tremaining: 59.2s\n",
            "333:\tlearn: 0.1910052\ttotal: 29.6s\tremaining: 59s\n",
            "334:\tlearn: 0.1909745\ttotal: 29.7s\tremaining: 58.9s\n",
            "335:\tlearn: 0.1909428\ttotal: 29.7s\tremaining: 58.8s\n",
            "336:\tlearn: 0.1909058\ttotal: 29.9s\tremaining: 58.7s\n",
            "337:\tlearn: 0.1908368\ttotal: 30s\tremaining: 58.7s\n",
            "338:\tlearn: 0.1908129\ttotal: 30.2s\tremaining: 58.8s\n",
            "339:\tlearn: 0.1907844\ttotal: 30.3s\tremaining: 58.8s\n",
            "340:\tlearn: 0.1907418\ttotal: 30.4s\tremaining: 58.7s\n",
            "341:\tlearn: 0.1907129\ttotal: 30.4s\tremaining: 58.5s\n",
            "342:\tlearn: 0.1906917\ttotal: 30.5s\tremaining: 58.4s\n",
            "343:\tlearn: 0.1906706\ttotal: 30.6s\tremaining: 58.3s\n",
            "344:\tlearn: 0.1906437\ttotal: 30.7s\tremaining: 58.2s\n",
            "345:\tlearn: 0.1905904\ttotal: 30.8s\tremaining: 58.3s\n",
            "346:\tlearn: 0.1905363\ttotal: 31s\tremaining: 58.3s\n",
            "347:\tlearn: 0.1905078\ttotal: 31.1s\tremaining: 58.3s\n",
            "348:\tlearn: 0.1904554\ttotal: 31.2s\tremaining: 58.3s\n",
            "349:\tlearn: 0.1904287\ttotal: 31.4s\tremaining: 58.3s\n",
            "350:\tlearn: 0.1903988\ttotal: 31.5s\tremaining: 58.2s\n",
            "351:\tlearn: 0.1903564\ttotal: 31.6s\tremaining: 58.2s\n",
            "352:\tlearn: 0.1903097\ttotal: 31.8s\tremaining: 58.2s\n",
            "353:\tlearn: 0.1902899\ttotal: 31.9s\tremaining: 58.2s\n",
            "354:\tlearn: 0.1902537\ttotal: 32s\tremaining: 58.1s\n",
            "355:\tlearn: 0.1902382\ttotal: 32.1s\tremaining: 58.1s\n",
            "356:\tlearn: 0.1902181\ttotal: 32.2s\tremaining: 58.1s\n",
            "357:\tlearn: 0.1901628\ttotal: 32.4s\tremaining: 58.1s\n",
            "358:\tlearn: 0.1901349\ttotal: 32.5s\tremaining: 58s\n",
            "359:\tlearn: 0.1901090\ttotal: 32.7s\tremaining: 58.1s\n",
            "360:\tlearn: 0.1900955\ttotal: 32.8s\tremaining: 58.1s\n",
            "361:\tlearn: 0.1900606\ttotal: 33s\tremaining: 58.1s\n",
            "362:\tlearn: 0.1900236\ttotal: 33.1s\tremaining: 58.1s\n",
            "363:\tlearn: 0.1900053\ttotal: 33.3s\tremaining: 58.1s\n",
            "364:\tlearn: 0.1899808\ttotal: 33.4s\tremaining: 58.1s\n",
            "365:\tlearn: 0.1899172\ttotal: 33.5s\tremaining: 58.1s\n",
            "366:\tlearn: 0.1898967\ttotal: 33.6s\tremaining: 58s\n",
            "367:\tlearn: 0.1898740\ttotal: 33.8s\tremaining: 58s\n",
            "368:\tlearn: 0.1898408\ttotal: 33.9s\tremaining: 57.9s\n",
            "369:\tlearn: 0.1898156\ttotal: 34s\tremaining: 57.9s\n",
            "370:\tlearn: 0.1897838\ttotal: 34.1s\tremaining: 57.8s\n",
            "371:\tlearn: 0.1897409\ttotal: 34.2s\tremaining: 57.8s\n",
            "372:\tlearn: 0.1897010\ttotal: 34.4s\tremaining: 57.8s\n",
            "373:\tlearn: 0.1896524\ttotal: 34.5s\tremaining: 57.8s\n",
            "374:\tlearn: 0.1896270\ttotal: 34.7s\tremaining: 57.8s\n",
            "375:\tlearn: 0.1896028\ttotal: 34.8s\tremaining: 57.7s\n",
            "376:\tlearn: 0.1895683\ttotal: 34.9s\tremaining: 57.7s\n",
            "377:\tlearn: 0.1895301\ttotal: 35s\tremaining: 57.6s\n",
            "378:\tlearn: 0.1895022\ttotal: 35.2s\tremaining: 57.6s\n",
            "379:\tlearn: 0.1894835\ttotal: 35.3s\tremaining: 57.6s\n",
            "380:\tlearn: 0.1894528\ttotal: 35.4s\tremaining: 57.5s\n",
            "381:\tlearn: 0.1894090\ttotal: 35.5s\tremaining: 57.5s\n",
            "382:\tlearn: 0.1893725\ttotal: 35.7s\tremaining: 57.4s\n",
            "383:\tlearn: 0.1893531\ttotal: 35.8s\tremaining: 57.4s\n",
            "384:\tlearn: 0.1893257\ttotal: 35.9s\tremaining: 57.4s\n",
            "385:\tlearn: 0.1893087\ttotal: 36.2s\tremaining: 57.5s\n",
            "386:\tlearn: 0.1892666\ttotal: 36.3s\tremaining: 57.6s\n",
            "387:\tlearn: 0.1892340\ttotal: 36.5s\tremaining: 57.6s\n",
            "388:\tlearn: 0.1892134\ttotal: 36.7s\tremaining: 57.6s\n",
            "389:\tlearn: 0.1892000\ttotal: 36.8s\tremaining: 57.5s\n",
            "390:\tlearn: 0.1891873\ttotal: 36.8s\tremaining: 57.4s\n",
            "391:\tlearn: 0.1891575\ttotal: 36.9s\tremaining: 57.2s\n",
            "392:\tlearn: 0.1891401\ttotal: 36.9s\tremaining: 57.1s\n",
            "393:\tlearn: 0.1891116\ttotal: 37.1s\tremaining: 57s\n",
            "394:\tlearn: 0.1890993\ttotal: 37.1s\tremaining: 56.9s\n",
            "395:\tlearn: 0.1890793\ttotal: 37.2s\tremaining: 56.7s\n",
            "396:\tlearn: 0.1890658\ttotal: 37.2s\tremaining: 56.6s\n",
            "397:\tlearn: 0.1890393\ttotal: 37.3s\tremaining: 56.5s\n",
            "398:\tlearn: 0.1890133\ttotal: 37.4s\tremaining: 56.4s\n",
            "399:\tlearn: 0.1889794\ttotal: 37.5s\tremaining: 56.2s\n",
            "400:\tlearn: 0.1889564\ttotal: 37.5s\tremaining: 56s\n",
            "401:\tlearn: 0.1889394\ttotal: 37.6s\tremaining: 55.9s\n",
            "402:\tlearn: 0.1889091\ttotal: 37.6s\tremaining: 55.8s\n",
            "403:\tlearn: 0.1888798\ttotal: 37.8s\tremaining: 55.7s\n",
            "404:\tlearn: 0.1888531\ttotal: 37.9s\tremaining: 55.7s\n",
            "405:\tlearn: 0.1888254\ttotal: 38s\tremaining: 55.6s\n",
            "406:\tlearn: 0.1887936\ttotal: 38.1s\tremaining: 55.5s\n",
            "407:\tlearn: 0.1887737\ttotal: 38.2s\tremaining: 55.4s\n",
            "408:\tlearn: 0.1887613\ttotal: 38.3s\tremaining: 55.3s\n",
            "409:\tlearn: 0.1887400\ttotal: 38.4s\tremaining: 55.3s\n",
            "410:\tlearn: 0.1887213\ttotal: 38.5s\tremaining: 55.2s\n",
            "411:\tlearn: 0.1886848\ttotal: 38.6s\tremaining: 55.1s\n",
            "412:\tlearn: 0.1886582\ttotal: 38.6s\tremaining: 54.9s\n",
            "413:\tlearn: 0.1886350\ttotal: 38.7s\tremaining: 54.8s\n",
            "414:\tlearn: 0.1886093\ttotal: 38.8s\tremaining: 54.7s\n",
            "415:\tlearn: 0.1885891\ttotal: 38.9s\tremaining: 54.6s\n",
            "416:\tlearn: 0.1885610\ttotal: 38.9s\tremaining: 54.4s\n",
            "417:\tlearn: 0.1885249\ttotal: 39s\tremaining: 54.3s\n",
            "418:\tlearn: 0.1884950\ttotal: 39.1s\tremaining: 54.2s\n",
            "419:\tlearn: 0.1884609\ttotal: 39.2s\tremaining: 54.2s\n",
            "420:\tlearn: 0.1884155\ttotal: 39.3s\tremaining: 54.1s\n",
            "421:\tlearn: 0.1884065\ttotal: 39.4s\tremaining: 53.9s\n",
            "422:\tlearn: 0.1883629\ttotal: 39.4s\tremaining: 53.8s\n",
            "423:\tlearn: 0.1883453\ttotal: 39.5s\tremaining: 53.7s\n",
            "424:\tlearn: 0.1883196\ttotal: 39.6s\tremaining: 53.6s\n",
            "425:\tlearn: 0.1882894\ttotal: 39.8s\tremaining: 53.6s\n",
            "426:\tlearn: 0.1882437\ttotal: 40s\tremaining: 53.6s\n",
            "427:\tlearn: 0.1881860\ttotal: 40.2s\tremaining: 53.7s\n",
            "428:\tlearn: 0.1881479\ttotal: 40.2s\tremaining: 53.5s\n",
            "429:\tlearn: 0.1881204\ttotal: 40.3s\tremaining: 53.4s\n",
            "430:\tlearn: 0.1880860\ttotal: 40.3s\tremaining: 53.2s\n",
            "431:\tlearn: 0.1880558\ttotal: 40.5s\tremaining: 53.2s\n",
            "432:\tlearn: 0.1880309\ttotal: 40.6s\tremaining: 53.2s\n",
            "433:\tlearn: 0.1879866\ttotal: 40.7s\tremaining: 53.1s\n",
            "434:\tlearn: 0.1879562\ttotal: 40.9s\tremaining: 53.2s\n",
            "435:\tlearn: 0.1878968\ttotal: 41s\tremaining: 53s\n",
            "436:\tlearn: 0.1878709\ttotal: 41s\tremaining: 52.9s\n",
            "437:\tlearn: 0.1878426\ttotal: 41.1s\tremaining: 52.7s\n",
            "438:\tlearn: 0.1878008\ttotal: 41.2s\tremaining: 52.6s\n",
            "439:\tlearn: 0.1877570\ttotal: 41.3s\tremaining: 52.5s\n",
            "440:\tlearn: 0.1877374\ttotal: 41.3s\tremaining: 52.4s\n",
            "441:\tlearn: 0.1876930\ttotal: 41.4s\tremaining: 52.3s\n",
            "442:\tlearn: 0.1876594\ttotal: 41.5s\tremaining: 52.1s\n",
            "443:\tlearn: 0.1876012\ttotal: 41.5s\tremaining: 52s\n",
            "444:\tlearn: 0.1875936\ttotal: 41.7s\tremaining: 51.9s\n",
            "445:\tlearn: 0.1875691\ttotal: 41.8s\tremaining: 51.9s\n",
            "446:\tlearn: 0.1875247\ttotal: 41.8s\tremaining: 51.8s\n",
            "447:\tlearn: 0.1874910\ttotal: 41.9s\tremaining: 51.6s\n",
            "448:\tlearn: 0.1874737\ttotal: 42s\tremaining: 51.5s\n",
            "449:\tlearn: 0.1874577\ttotal: 42s\tremaining: 51.4s\n",
            "450:\tlearn: 0.1874313\ttotal: 42.2s\tremaining: 51.3s\n",
            "451:\tlearn: 0.1874030\ttotal: 42.3s\tremaining: 51.2s\n",
            "452:\tlearn: 0.1873703\ttotal: 42.3s\tremaining: 51.1s\n",
            "453:\tlearn: 0.1873371\ttotal: 42.4s\tremaining: 51s\n",
            "454:\tlearn: 0.1873097\ttotal: 42.4s\tremaining: 50.8s\n",
            "455:\tlearn: 0.1872823\ttotal: 42.5s\tremaining: 50.7s\n",
            "456:\tlearn: 0.1872510\ttotal: 42.6s\tremaining: 50.6s\n",
            "457:\tlearn: 0.1872362\ttotal: 42.8s\tremaining: 50.6s\n",
            "458:\tlearn: 0.1872116\ttotal: 42.9s\tremaining: 50.6s\n",
            "459:\tlearn: 0.1871818\ttotal: 43s\tremaining: 50.5s\n",
            "460:\tlearn: 0.1871639\ttotal: 43.2s\tremaining: 50.5s\n",
            "461:\tlearn: 0.1871332\ttotal: 43.3s\tremaining: 50.5s\n",
            "462:\tlearn: 0.1870796\ttotal: 43.4s\tremaining: 50.4s\n",
            "463:\tlearn: 0.1870466\ttotal: 43.6s\tremaining: 50.3s\n",
            "464:\tlearn: 0.1870132\ttotal: 43.7s\tremaining: 50.3s\n",
            "465:\tlearn: 0.1869900\ttotal: 43.8s\tremaining: 50.2s\n",
            "466:\tlearn: 0.1869644\ttotal: 43.9s\tremaining: 50.1s\n",
            "467:\tlearn: 0.1869400\ttotal: 44.1s\tremaining: 50.1s\n",
            "468:\tlearn: 0.1868917\ttotal: 44.2s\tremaining: 50s\n",
            "469:\tlearn: 0.1868572\ttotal: 44.3s\tremaining: 50s\n",
            "470:\tlearn: 0.1868374\ttotal: 44.4s\tremaining: 49.9s\n",
            "471:\tlearn: 0.1868095\ttotal: 44.6s\tremaining: 49.9s\n",
            "472:\tlearn: 0.1867829\ttotal: 44.7s\tremaining: 49.8s\n",
            "473:\tlearn: 0.1867369\ttotal: 44.9s\tremaining: 49.8s\n",
            "474:\tlearn: 0.1866949\ttotal: 45s\tremaining: 49.8s\n",
            "475:\tlearn: 0.1866710\ttotal: 45.1s\tremaining: 49.7s\n",
            "476:\tlearn: 0.1866560\ttotal: 45.3s\tremaining: 49.6s\n",
            "477:\tlearn: 0.1866279\ttotal: 45.4s\tremaining: 49.5s\n",
            "478:\tlearn: 0.1866079\ttotal: 45.5s\tremaining: 49.5s\n",
            "479:\tlearn: 0.1865817\ttotal: 45.6s\tremaining: 49.4s\n",
            "480:\tlearn: 0.1865553\ttotal: 45.7s\tremaining: 49.3s\n",
            "481:\tlearn: 0.1865081\ttotal: 45.8s\tremaining: 49.2s\n",
            "482:\tlearn: 0.1864812\ttotal: 45.9s\tremaining: 49.1s\n",
            "483:\tlearn: 0.1864593\ttotal: 46s\tremaining: 49.1s\n",
            "484:\tlearn: 0.1864236\ttotal: 46.1s\tremaining: 49s\n",
            "485:\tlearn: 0.1863877\ttotal: 46.3s\tremaining: 49s\n",
            "486:\tlearn: 0.1863515\ttotal: 46.4s\tremaining: 48.9s\n",
            "487:\tlearn: 0.1863291\ttotal: 46.6s\tremaining: 48.8s\n",
            "488:\tlearn: 0.1863032\ttotal: 46.7s\tremaining: 48.8s\n",
            "489:\tlearn: 0.1862840\ttotal: 46.9s\tremaining: 48.8s\n",
            "490:\tlearn: 0.1862598\ttotal: 47.1s\tremaining: 48.8s\n",
            "491:\tlearn: 0.1862326\ttotal: 47.2s\tremaining: 48.7s\n",
            "492:\tlearn: 0.1862124\ttotal: 47.3s\tremaining: 48.7s\n",
            "493:\tlearn: 0.1861940\ttotal: 47.5s\tremaining: 48.6s\n",
            "494:\tlearn: 0.1861684\ttotal: 47.6s\tremaining: 48.5s\n",
            "495:\tlearn: 0.1861388\ttotal: 47.7s\tremaining: 48.5s\n",
            "496:\tlearn: 0.1861128\ttotal: 47.8s\tremaining: 48.4s\n",
            "497:\tlearn: 0.1860789\ttotal: 48s\tremaining: 48.3s\n",
            "498:\tlearn: 0.1860442\ttotal: 48.1s\tremaining: 48.3s\n",
            "499:\tlearn: 0.1860326\ttotal: 48.2s\tremaining: 48.2s\n",
            "500:\tlearn: 0.1860005\ttotal: 48.3s\tremaining: 48.1s\n",
            "501:\tlearn: 0.1859660\ttotal: 48.4s\tremaining: 48s\n",
            "502:\tlearn: 0.1859474\ttotal: 48.5s\tremaining: 48s\n",
            "503:\tlearn: 0.1859149\ttotal: 48.6s\tremaining: 47.9s\n",
            "504:\tlearn: 0.1858863\ttotal: 48.7s\tremaining: 47.8s\n",
            "505:\tlearn: 0.1858735\ttotal: 48.8s\tremaining: 47.6s\n",
            "506:\tlearn: 0.1858504\ttotal: 48.9s\tremaining: 47.5s\n",
            "507:\tlearn: 0.1858288\ttotal: 49s\tremaining: 47.4s\n",
            "508:\tlearn: 0.1858020\ttotal: 49s\tremaining: 47.3s\n",
            "509:\tlearn: 0.1857893\ttotal: 49.1s\tremaining: 47.2s\n",
            "510:\tlearn: 0.1857578\ttotal: 49.1s\tremaining: 47s\n",
            "511:\tlearn: 0.1857330\ttotal: 49.3s\tremaining: 47s\n",
            "512:\tlearn: 0.1857125\ttotal: 49.4s\tremaining: 46.9s\n",
            "513:\tlearn: 0.1856934\ttotal: 49.5s\tremaining: 46.8s\n",
            "514:\tlearn: 0.1856479\ttotal: 49.6s\tremaining: 46.7s\n",
            "515:\tlearn: 0.1856203\ttotal: 49.8s\tremaining: 46.7s\n",
            "516:\tlearn: 0.1856041\ttotal: 49.9s\tremaining: 46.6s\n",
            "517:\tlearn: 0.1855720\ttotal: 50s\tremaining: 46.5s\n",
            "518:\tlearn: 0.1855440\ttotal: 50.1s\tremaining: 46.4s\n",
            "519:\tlearn: 0.1855194\ttotal: 50.2s\tremaining: 46.3s\n",
            "520:\tlearn: 0.1855003\ttotal: 50.3s\tremaining: 46.3s\n",
            "521:\tlearn: 0.1854667\ttotal: 50.5s\tremaining: 46.2s\n",
            "522:\tlearn: 0.1854430\ttotal: 50.6s\tremaining: 46.1s\n",
            "523:\tlearn: 0.1854288\ttotal: 50.7s\tremaining: 46.1s\n",
            "524:\tlearn: 0.1853962\ttotal: 50.8s\tremaining: 46s\n",
            "525:\tlearn: 0.1853807\ttotal: 50.9s\tremaining: 45.9s\n",
            "526:\tlearn: 0.1853335\ttotal: 51.1s\tremaining: 45.8s\n",
            "527:\tlearn: 0.1853043\ttotal: 51.2s\tremaining: 45.8s\n",
            "528:\tlearn: 0.1852754\ttotal: 51.3s\tremaining: 45.7s\n",
            "529:\tlearn: 0.1852457\ttotal: 51.4s\tremaining: 45.6s\n",
            "530:\tlearn: 0.1852180\ttotal: 51.6s\tremaining: 45.5s\n",
            "531:\tlearn: 0.1851711\ttotal: 51.7s\tremaining: 45.5s\n",
            "532:\tlearn: 0.1851445\ttotal: 51.8s\tremaining: 45.4s\n",
            "533:\tlearn: 0.1851153\ttotal: 51.9s\tremaining: 45.3s\n",
            "534:\tlearn: 0.1851009\ttotal: 52.1s\tremaining: 45.3s\n",
            "535:\tlearn: 0.1850669\ttotal: 52.2s\tremaining: 45.2s\n",
            "536:\tlearn: 0.1850404\ttotal: 52.3s\tremaining: 45.1s\n",
            "537:\tlearn: 0.1850072\ttotal: 52.4s\tremaining: 45s\n",
            "538:\tlearn: 0.1849842\ttotal: 52.6s\tremaining: 44.9s\n",
            "539:\tlearn: 0.1849295\ttotal: 52.7s\tremaining: 44.9s\n",
            "540:\tlearn: 0.1849161\ttotal: 52.8s\tremaining: 44.8s\n",
            "541:\tlearn: 0.1848846\ttotal: 53s\tremaining: 44.8s\n",
            "542:\tlearn: 0.1848585\ttotal: 53.1s\tremaining: 44.7s\n",
            "543:\tlearn: 0.1848255\ttotal: 53.3s\tremaining: 44.7s\n",
            "544:\tlearn: 0.1848112\ttotal: 53.4s\tremaining: 44.6s\n",
            "545:\tlearn: 0.1847919\ttotal: 53.5s\tremaining: 44.4s\n",
            "546:\tlearn: 0.1847808\ttotal: 53.5s\tremaining: 44.3s\n",
            "547:\tlearn: 0.1847610\ttotal: 53.7s\tremaining: 44.3s\n",
            "548:\tlearn: 0.1847302\ttotal: 53.7s\tremaining: 44.1s\n",
            "549:\tlearn: 0.1846806\ttotal: 53.8s\tremaining: 44s\n",
            "550:\tlearn: 0.1846564\ttotal: 53.9s\tremaining: 43.9s\n",
            "551:\tlearn: 0.1846276\ttotal: 53.9s\tremaining: 43.8s\n",
            "552:\tlearn: 0.1846049\ttotal: 54s\tremaining: 43.7s\n",
            "553:\tlearn: 0.1845807\ttotal: 54.1s\tremaining: 43.6s\n",
            "554:\tlearn: 0.1845330\ttotal: 54.2s\tremaining: 43.5s\n",
            "555:\tlearn: 0.1845193\ttotal: 54.2s\tremaining: 43.3s\n",
            "556:\tlearn: 0.1844997\ttotal: 54.3s\tremaining: 43.2s\n",
            "557:\tlearn: 0.1844752\ttotal: 54.4s\tremaining: 43.1s\n",
            "558:\tlearn: 0.1844557\ttotal: 54.4s\tremaining: 42.9s\n",
            "559:\tlearn: 0.1844378\ttotal: 54.6s\tremaining: 42.9s\n",
            "560:\tlearn: 0.1844077\ttotal: 54.6s\tremaining: 42.8s\n",
            "561:\tlearn: 0.1843636\ttotal: 54.7s\tremaining: 42.6s\n",
            "562:\tlearn: 0.1843481\ttotal: 54.7s\tremaining: 42.5s\n",
            "563:\tlearn: 0.1843296\ttotal: 54.8s\tremaining: 42.4s\n",
            "564:\tlearn: 0.1843148\ttotal: 54.9s\tremaining: 42.3s\n",
            "565:\tlearn: 0.1842931\ttotal: 55.1s\tremaining: 42.2s\n",
            "566:\tlearn: 0.1842626\ttotal: 55.1s\tremaining: 42.1s\n",
            "567:\tlearn: 0.1842357\ttotal: 55.2s\tremaining: 42s\n",
            "568:\tlearn: 0.1842183\ttotal: 55.3s\tremaining: 41.9s\n",
            "569:\tlearn: 0.1841827\ttotal: 55.3s\tremaining: 41.7s\n",
            "570:\tlearn: 0.1841588\ttotal: 55.5s\tremaining: 41.7s\n",
            "571:\tlearn: 0.1841314\ttotal: 55.5s\tremaining: 41.5s\n",
            "572:\tlearn: 0.1841177\ttotal: 55.6s\tremaining: 41.4s\n",
            "573:\tlearn: 0.1840741\ttotal: 55.6s\tremaining: 41.3s\n",
            "574:\tlearn: 0.1840436\ttotal: 55.7s\tremaining: 41.2s\n",
            "575:\tlearn: 0.1840216\ttotal: 55.8s\tremaining: 41.1s\n",
            "576:\tlearn: 0.1839955\ttotal: 55.9s\tremaining: 41s\n",
            "577:\tlearn: 0.1839760\ttotal: 55.9s\tremaining: 40.8s\n",
            "578:\tlearn: 0.1839571\ttotal: 56s\tremaining: 40.7s\n",
            "579:\tlearn: 0.1839283\ttotal: 56s\tremaining: 40.6s\n",
            "580:\tlearn: 0.1838860\ttotal: 56.1s\tremaining: 40.5s\n",
            "581:\tlearn: 0.1838466\ttotal: 56.2s\tremaining: 40.4s\n",
            "582:\tlearn: 0.1838233\ttotal: 56.3s\tremaining: 40.3s\n",
            "583:\tlearn: 0.1838023\ttotal: 56.3s\tremaining: 40.1s\n",
            "584:\tlearn: 0.1837741\ttotal: 56.4s\tremaining: 40s\n",
            "585:\tlearn: 0.1837434\ttotal: 56.5s\tremaining: 39.9s\n",
            "586:\tlearn: 0.1837341\ttotal: 56.6s\tremaining: 39.8s\n",
            "587:\tlearn: 0.1837130\ttotal: 56.7s\tremaining: 39.7s\n",
            "588:\tlearn: 0.1836890\ttotal: 56.8s\tremaining: 39.7s\n",
            "589:\tlearn: 0.1836749\ttotal: 56.9s\tremaining: 39.5s\n",
            "590:\tlearn: 0.1836546\ttotal: 56.9s\tremaining: 39.4s\n",
            "591:\tlearn: 0.1836399\ttotal: 57s\tremaining: 39.3s\n",
            "592:\tlearn: 0.1836079\ttotal: 57.1s\tremaining: 39.2s\n",
            "593:\tlearn: 0.1835808\ttotal: 57.2s\tremaining: 39.1s\n",
            "594:\tlearn: 0.1835600\ttotal: 57.3s\tremaining: 39s\n",
            "595:\tlearn: 0.1835458\ttotal: 57.3s\tremaining: 38.9s\n",
            "596:\tlearn: 0.1835087\ttotal: 57.4s\tremaining: 38.8s\n",
            "597:\tlearn: 0.1834954\ttotal: 57.5s\tremaining: 38.6s\n",
            "598:\tlearn: 0.1834722\ttotal: 57.6s\tremaining: 38.5s\n",
            "599:\tlearn: 0.1834448\ttotal: 57.7s\tremaining: 38.4s\n",
            "600:\tlearn: 0.1834167\ttotal: 57.7s\tremaining: 38.3s\n",
            "601:\tlearn: 0.1833595\ttotal: 57.8s\tremaining: 38.2s\n",
            "602:\tlearn: 0.1833402\ttotal: 57.8s\tremaining: 38.1s\n",
            "603:\tlearn: 0.1832988\ttotal: 57.9s\tremaining: 38s\n",
            "604:\tlearn: 0.1832684\ttotal: 58s\tremaining: 37.9s\n",
            "605:\tlearn: 0.1832362\ttotal: 58.1s\tremaining: 37.8s\n",
            "606:\tlearn: 0.1832143\ttotal: 58.3s\tremaining: 37.7s\n",
            "607:\tlearn: 0.1831933\ttotal: 58.4s\tremaining: 37.6s\n",
            "608:\tlearn: 0.1831766\ttotal: 58.4s\tremaining: 37.5s\n",
            "609:\tlearn: 0.1831336\ttotal: 58.6s\tremaining: 37.4s\n",
            "610:\tlearn: 0.1830990\ttotal: 58.6s\tremaining: 37.3s\n",
            "611:\tlearn: 0.1830721\ttotal: 58.7s\tremaining: 37.2s\n",
            "612:\tlearn: 0.1830511\ttotal: 58.7s\tremaining: 37.1s\n",
            "613:\tlearn: 0.1830201\ttotal: 58.8s\tremaining: 37s\n",
            "614:\tlearn: 0.1830005\ttotal: 58.9s\tremaining: 36.9s\n",
            "615:\tlearn: 0.1829841\ttotal: 59s\tremaining: 36.8s\n",
            "616:\tlearn: 0.1829557\ttotal: 59.1s\tremaining: 36.7s\n",
            "617:\tlearn: 0.1829130\ttotal: 59.2s\tremaining: 36.6s\n",
            "618:\tlearn: 0.1828943\ttotal: 59.2s\tremaining: 36.4s\n",
            "619:\tlearn: 0.1828764\ttotal: 59.3s\tremaining: 36.4s\n",
            "620:\tlearn: 0.1828562\ttotal: 59.4s\tremaining: 36.2s\n",
            "621:\tlearn: 0.1828301\ttotal: 59.4s\tremaining: 36.1s\n",
            "622:\tlearn: 0.1827945\ttotal: 59.5s\tremaining: 36s\n",
            "623:\tlearn: 0.1827697\ttotal: 59.6s\tremaining: 35.9s\n",
            "624:\tlearn: 0.1827305\ttotal: 59.7s\tremaining: 35.8s\n",
            "625:\tlearn: 0.1826880\ttotal: 59.8s\tremaining: 35.7s\n",
            "626:\tlearn: 0.1826719\ttotal: 59.9s\tremaining: 35.6s\n",
            "627:\tlearn: 0.1826572\ttotal: 1m\tremaining: 35.6s\n",
            "628:\tlearn: 0.1826450\ttotal: 1m\tremaining: 35.5s\n",
            "629:\tlearn: 0.1826175\ttotal: 1m\tremaining: 35.4s\n",
            "630:\tlearn: 0.1825819\ttotal: 1m\tremaining: 35.3s\n",
            "631:\tlearn: 0.1825360\ttotal: 1m\tremaining: 35.3s\n",
            "632:\tlearn: 0.1825093\ttotal: 1m\tremaining: 35.2s\n",
            "633:\tlearn: 0.1824901\ttotal: 1m\tremaining: 35s\n",
            "634:\tlearn: 0.1824564\ttotal: 1m\tremaining: 34.9s\n",
            "635:\tlearn: 0.1824374\ttotal: 1m\tremaining: 34.8s\n",
            "636:\tlearn: 0.1824125\ttotal: 1m\tremaining: 34.7s\n",
            "637:\tlearn: 0.1823856\ttotal: 1m 1s\tremaining: 34.6s\n",
            "638:\tlearn: 0.1823581\ttotal: 1m 1s\tremaining: 34.5s\n",
            "639:\tlearn: 0.1823437\ttotal: 1m 1s\tremaining: 34.4s\n",
            "640:\tlearn: 0.1823048\ttotal: 1m 1s\tremaining: 34.3s\n",
            "641:\tlearn: 0.1822900\ttotal: 1m 1s\tremaining: 34.1s\n",
            "642:\tlearn: 0.1822589\ttotal: 1m 1s\tremaining: 34.1s\n",
            "643:\tlearn: 0.1822432\ttotal: 1m 1s\tremaining: 34s\n",
            "644:\tlearn: 0.1822233\ttotal: 1m 1s\tremaining: 33.9s\n",
            "645:\tlearn: 0.1821757\ttotal: 1m 1s\tremaining: 33.7s\n",
            "646:\tlearn: 0.1821527\ttotal: 1m 1s\tremaining: 33.6s\n",
            "647:\tlearn: 0.1821271\ttotal: 1m 1s\tremaining: 33.5s\n",
            "648:\tlearn: 0.1821118\ttotal: 1m 1s\tremaining: 33.4s\n",
            "649:\tlearn: 0.1821024\ttotal: 1m 1s\tremaining: 33.3s\n",
            "650:\tlearn: 0.1820730\ttotal: 1m 1s\tremaining: 33.2s\n",
            "651:\tlearn: 0.1820624\ttotal: 1m 2s\tremaining: 33.1s\n",
            "652:\tlearn: 0.1820391\ttotal: 1m 2s\tremaining: 33s\n",
            "653:\tlearn: 0.1820102\ttotal: 1m 2s\tremaining: 32.9s\n",
            "654:\tlearn: 0.1819920\ttotal: 1m 2s\tremaining: 32.8s\n",
            "655:\tlearn: 0.1819610\ttotal: 1m 2s\tremaining: 32.7s\n",
            "656:\tlearn: 0.1819263\ttotal: 1m 2s\tremaining: 32.6s\n",
            "657:\tlearn: 0.1819019\ttotal: 1m 2s\tremaining: 32.5s\n",
            "658:\tlearn: 0.1818737\ttotal: 1m 2s\tremaining: 32.4s\n",
            "659:\tlearn: 0.1818571\ttotal: 1m 2s\tremaining: 32.3s\n",
            "660:\tlearn: 0.1818243\ttotal: 1m 2s\tremaining: 32.2s\n",
            "661:\tlearn: 0.1818103\ttotal: 1m 2s\tremaining: 32.1s\n",
            "662:\tlearn: 0.1817949\ttotal: 1m 3s\tremaining: 32s\n",
            "663:\tlearn: 0.1817680\ttotal: 1m 3s\tremaining: 31.9s\n",
            "664:\tlearn: 0.1817548\ttotal: 1m 3s\tremaining: 31.9s\n",
            "665:\tlearn: 0.1817366\ttotal: 1m 3s\tremaining: 31.8s\n",
            "666:\tlearn: 0.1817132\ttotal: 1m 3s\tremaining: 31.7s\n",
            "667:\tlearn: 0.1816945\ttotal: 1m 3s\tremaining: 31.6s\n",
            "668:\tlearn: 0.1816699\ttotal: 1m 3s\tremaining: 31.4s\n",
            "669:\tlearn: 0.1816536\ttotal: 1m 3s\tremaining: 31.3s\n",
            "670:\tlearn: 0.1816309\ttotal: 1m 3s\tremaining: 31.3s\n",
            "671:\tlearn: 0.1816129\ttotal: 1m 3s\tremaining: 31.2s\n",
            "672:\tlearn: 0.1815874\ttotal: 1m 3s\tremaining: 31s\n",
            "673:\tlearn: 0.1815603\ttotal: 1m 3s\tremaining: 30.9s\n",
            "674:\tlearn: 0.1815392\ttotal: 1m 4s\tremaining: 30.8s\n",
            "675:\tlearn: 0.1815035\ttotal: 1m 4s\tremaining: 30.7s\n",
            "676:\tlearn: 0.1814676\ttotal: 1m 4s\tremaining: 30.6s\n",
            "677:\tlearn: 0.1814400\ttotal: 1m 4s\tremaining: 30.5s\n",
            "678:\tlearn: 0.1814179\ttotal: 1m 4s\tremaining: 30.4s\n",
            "679:\tlearn: 0.1813701\ttotal: 1m 4s\tremaining: 30.3s\n",
            "680:\tlearn: 0.1813565\ttotal: 1m 4s\tremaining: 30.2s\n",
            "681:\tlearn: 0.1813468\ttotal: 1m 4s\tremaining: 30.1s\n",
            "682:\tlearn: 0.1813118\ttotal: 1m 4s\tremaining: 30s\n",
            "683:\tlearn: 0.1812760\ttotal: 1m 4s\tremaining: 29.9s\n",
            "684:\tlearn: 0.1812649\ttotal: 1m 4s\tremaining: 29.8s\n",
            "685:\tlearn: 0.1812465\ttotal: 1m 4s\tremaining: 29.7s\n",
            "686:\tlearn: 0.1812128\ttotal: 1m 4s\tremaining: 29.6s\n",
            "687:\tlearn: 0.1811535\ttotal: 1m 5s\tremaining: 29.5s\n",
            "688:\tlearn: 0.1811336\ttotal: 1m 5s\tremaining: 29.4s\n",
            "689:\tlearn: 0.1811118\ttotal: 1m 5s\tremaining: 29.3s\n",
            "690:\tlearn: 0.1810832\ttotal: 1m 5s\tremaining: 29.2s\n",
            "691:\tlearn: 0.1810578\ttotal: 1m 5s\tremaining: 29.1s\n",
            "692:\tlearn: 0.1810421\ttotal: 1m 5s\tremaining: 29s\n",
            "693:\tlearn: 0.1810267\ttotal: 1m 5s\tremaining: 28.9s\n",
            "694:\tlearn: 0.1810104\ttotal: 1m 5s\tremaining: 28.8s\n",
            "695:\tlearn: 0.1809916\ttotal: 1m 5s\tremaining: 28.7s\n",
            "696:\tlearn: 0.1809620\ttotal: 1m 5s\tremaining: 28.6s\n",
            "697:\tlearn: 0.1809276\ttotal: 1m 5s\tremaining: 28.5s\n",
            "698:\tlearn: 0.1808941\ttotal: 1m 6s\tremaining: 28.5s\n",
            "699:\tlearn: 0.1808766\ttotal: 1m 6s\tremaining: 28.4s\n",
            "700:\tlearn: 0.1808601\ttotal: 1m 6s\tremaining: 28.3s\n",
            "701:\tlearn: 0.1808342\ttotal: 1m 6s\tremaining: 28.2s\n",
            "702:\tlearn: 0.1808218\ttotal: 1m 6s\tremaining: 28.1s\n",
            "703:\tlearn: 0.1807692\ttotal: 1m 6s\tremaining: 28s\n",
            "704:\tlearn: 0.1807491\ttotal: 1m 6s\tremaining: 28s\n",
            "705:\tlearn: 0.1807320\ttotal: 1m 6s\tremaining: 27.9s\n",
            "706:\tlearn: 0.1807177\ttotal: 1m 6s\tremaining: 27.8s\n",
            "707:\tlearn: 0.1806964\ttotal: 1m 7s\tremaining: 27.7s\n",
            "708:\tlearn: 0.1806572\ttotal: 1m 7s\tremaining: 27.6s\n",
            "709:\tlearn: 0.1806306\ttotal: 1m 7s\tremaining: 27.5s\n",
            "710:\tlearn: 0.1806167\ttotal: 1m 7s\tremaining: 27.4s\n",
            "711:\tlearn: 0.1806007\ttotal: 1m 7s\tremaining: 27.4s\n",
            "712:\tlearn: 0.1805883\ttotal: 1m 7s\tremaining: 27.3s\n",
            "713:\tlearn: 0.1805730\ttotal: 1m 7s\tremaining: 27.2s\n",
            "714:\tlearn: 0.1805616\ttotal: 1m 8s\tremaining: 27.1s\n",
            "715:\tlearn: 0.1805418\ttotal: 1m 8s\tremaining: 27s\n",
            "716:\tlearn: 0.1805265\ttotal: 1m 8s\tremaining: 26.9s\n",
            "717:\tlearn: 0.1805082\ttotal: 1m 8s\tremaining: 26.9s\n",
            "718:\tlearn: 0.1804866\ttotal: 1m 8s\tremaining: 26.8s\n",
            "719:\tlearn: 0.1804632\ttotal: 1m 8s\tremaining: 26.7s\n",
            "720:\tlearn: 0.1804390\ttotal: 1m 8s\tremaining: 26.6s\n",
            "721:\tlearn: 0.1804289\ttotal: 1m 8s\tremaining: 26.5s\n",
            "722:\tlearn: 0.1804099\ttotal: 1m 8s\tremaining: 26.4s\n",
            "723:\tlearn: 0.1803885\ttotal: 1m 9s\tremaining: 26.3s\n",
            "724:\tlearn: 0.1803701\ttotal: 1m 9s\tremaining: 26.3s\n",
            "725:\tlearn: 0.1803557\ttotal: 1m 9s\tremaining: 26.2s\n",
            "726:\tlearn: 0.1803097\ttotal: 1m 9s\tremaining: 26.1s\n",
            "727:\tlearn: 0.1802996\ttotal: 1m 9s\tremaining: 26s\n",
            "728:\tlearn: 0.1802817\ttotal: 1m 9s\tremaining: 26s\n",
            "729:\tlearn: 0.1802569\ttotal: 1m 10s\tremaining: 25.9s\n",
            "730:\tlearn: 0.1802100\ttotal: 1m 10s\tremaining: 25.9s\n",
            "731:\tlearn: 0.1801820\ttotal: 1m 10s\tremaining: 25.8s\n",
            "732:\tlearn: 0.1801520\ttotal: 1m 10s\tremaining: 25.7s\n",
            "733:\tlearn: 0.1801304\ttotal: 1m 10s\tremaining: 25.6s\n",
            "734:\tlearn: 0.1801012\ttotal: 1m 10s\tremaining: 25.6s\n",
            "735:\tlearn: 0.1800916\ttotal: 1m 11s\tremaining: 25.5s\n",
            "736:\tlearn: 0.1800849\ttotal: 1m 11s\tremaining: 25.4s\n",
            "737:\tlearn: 0.1800552\ttotal: 1m 11s\tremaining: 25.3s\n",
            "738:\tlearn: 0.1800303\ttotal: 1m 11s\tremaining: 25.3s\n",
            "739:\tlearn: 0.1799975\ttotal: 1m 11s\tremaining: 25.2s\n",
            "740:\tlearn: 0.1799707\ttotal: 1m 11s\tremaining: 25.1s\n",
            "741:\tlearn: 0.1799427\ttotal: 1m 12s\tremaining: 25.1s\n",
            "742:\tlearn: 0.1799199\ttotal: 1m 12s\tremaining: 25s\n",
            "743:\tlearn: 0.1798904\ttotal: 1m 12s\tremaining: 24.9s\n",
            "744:\tlearn: 0.1798632\ttotal: 1m 12s\tremaining: 24.8s\n",
            "745:\tlearn: 0.1798238\ttotal: 1m 12s\tremaining: 24.7s\n",
            "746:\tlearn: 0.1798055\ttotal: 1m 12s\tremaining: 24.6s\n",
            "747:\tlearn: 0.1797772\ttotal: 1m 12s\tremaining: 24.5s\n",
            "748:\tlearn: 0.1797441\ttotal: 1m 12s\tremaining: 24.4s\n",
            "749:\tlearn: 0.1797053\ttotal: 1m 13s\tremaining: 24.3s\n",
            "750:\tlearn: 0.1796857\ttotal: 1m 13s\tremaining: 24.3s\n",
            "751:\tlearn: 0.1796568\ttotal: 1m 13s\tremaining: 24.2s\n",
            "752:\tlearn: 0.1796293\ttotal: 1m 13s\tremaining: 24.1s\n",
            "753:\tlearn: 0.1796106\ttotal: 1m 13s\tremaining: 24s\n",
            "754:\tlearn: 0.1795884\ttotal: 1m 13s\tremaining: 23.9s\n",
            "755:\tlearn: 0.1795659\ttotal: 1m 13s\tremaining: 23.8s\n",
            "756:\tlearn: 0.1795420\ttotal: 1m 13s\tremaining: 23.7s\n",
            "757:\tlearn: 0.1795306\ttotal: 1m 13s\tremaining: 23.6s\n",
            "758:\tlearn: 0.1795179\ttotal: 1m 14s\tremaining: 23.5s\n",
            "759:\tlearn: 0.1794981\ttotal: 1m 14s\tremaining: 23.4s\n",
            "760:\tlearn: 0.1794813\ttotal: 1m 14s\tremaining: 23.3s\n",
            "761:\tlearn: 0.1794619\ttotal: 1m 14s\tremaining: 23.3s\n",
            "762:\tlearn: 0.1794231\ttotal: 1m 14s\tremaining: 23.2s\n",
            "763:\tlearn: 0.1794010\ttotal: 1m 14s\tremaining: 23.1s\n",
            "764:\tlearn: 0.1793688\ttotal: 1m 14s\tremaining: 23s\n",
            "765:\tlearn: 0.1793409\ttotal: 1m 14s\tremaining: 22.9s\n",
            "766:\tlearn: 0.1793286\ttotal: 1m 15s\tremaining: 22.8s\n",
            "767:\tlearn: 0.1792932\ttotal: 1m 15s\tremaining: 22.7s\n",
            "768:\tlearn: 0.1792686\ttotal: 1m 15s\tremaining: 22.7s\n",
            "769:\tlearn: 0.1792410\ttotal: 1m 15s\tremaining: 22.6s\n",
            "770:\tlearn: 0.1792204\ttotal: 1m 15s\tremaining: 22.5s\n",
            "771:\tlearn: 0.1792008\ttotal: 1m 15s\tremaining: 22.4s\n",
            "772:\tlearn: 0.1791796\ttotal: 1m 15s\tremaining: 22.3s\n",
            "773:\tlearn: 0.1791639\ttotal: 1m 16s\tremaining: 22.2s\n",
            "774:\tlearn: 0.1791438\ttotal: 1m 16s\tremaining: 22.1s\n",
            "775:\tlearn: 0.1791250\ttotal: 1m 16s\tremaining: 22s\n",
            "776:\tlearn: 0.1791141\ttotal: 1m 16s\tremaining: 21.9s\n",
            "777:\tlearn: 0.1790925\ttotal: 1m 16s\tremaining: 21.8s\n",
            "778:\tlearn: 0.1790628\ttotal: 1m 16s\tremaining: 21.7s\n",
            "779:\tlearn: 0.1790282\ttotal: 1m 16s\tremaining: 21.6s\n",
            "780:\tlearn: 0.1790013\ttotal: 1m 16s\tremaining: 21.6s\n",
            "781:\tlearn: 0.1789752\ttotal: 1m 16s\tremaining: 21.5s\n",
            "782:\tlearn: 0.1789560\ttotal: 1m 17s\tremaining: 21.4s\n",
            "783:\tlearn: 0.1789364\ttotal: 1m 17s\tremaining: 21.3s\n",
            "784:\tlearn: 0.1789248\ttotal: 1m 17s\tremaining: 21.2s\n",
            "785:\tlearn: 0.1789017\ttotal: 1m 17s\tremaining: 21.1s\n",
            "786:\tlearn: 0.1788674\ttotal: 1m 17s\tremaining: 21s\n",
            "787:\tlearn: 0.1788355\ttotal: 1m 17s\tremaining: 20.9s\n",
            "788:\tlearn: 0.1788067\ttotal: 1m 17s\tremaining: 20.8s\n",
            "789:\tlearn: 0.1787833\ttotal: 1m 18s\tremaining: 20.7s\n",
            "790:\tlearn: 0.1787483\ttotal: 1m 18s\tremaining: 20.7s\n",
            "791:\tlearn: 0.1787315\ttotal: 1m 18s\tremaining: 20.6s\n",
            "792:\tlearn: 0.1787056\ttotal: 1m 18s\tremaining: 20.5s\n",
            "793:\tlearn: 0.1786743\ttotal: 1m 18s\tremaining: 20.4s\n",
            "794:\tlearn: 0.1786488\ttotal: 1m 18s\tremaining: 20.3s\n",
            "795:\tlearn: 0.1786266\ttotal: 1m 18s\tremaining: 20.2s\n",
            "796:\tlearn: 0.1786067\ttotal: 1m 18s\tremaining: 20.1s\n",
            "797:\tlearn: 0.1785921\ttotal: 1m 19s\tremaining: 20s\n",
            "798:\tlearn: 0.1785766\ttotal: 1m 19s\tremaining: 19.9s\n",
            "799:\tlearn: 0.1785526\ttotal: 1m 19s\tremaining: 19.8s\n",
            "800:\tlearn: 0.1785322\ttotal: 1m 19s\tremaining: 19.7s\n",
            "801:\tlearn: 0.1785164\ttotal: 1m 19s\tremaining: 19.6s\n",
            "802:\tlearn: 0.1784887\ttotal: 1m 19s\tremaining: 19.6s\n",
            "803:\tlearn: 0.1784456\ttotal: 1m 19s\tremaining: 19.5s\n",
            "804:\tlearn: 0.1784191\ttotal: 1m 19s\tremaining: 19.4s\n",
            "805:\tlearn: 0.1783922\ttotal: 1m 20s\tremaining: 19.3s\n",
            "806:\tlearn: 0.1783554\ttotal: 1m 20s\tremaining: 19.2s\n",
            "807:\tlearn: 0.1783373\ttotal: 1m 20s\tremaining: 19.1s\n",
            "808:\tlearn: 0.1783205\ttotal: 1m 20s\tremaining: 19s\n",
            "809:\tlearn: 0.1782982\ttotal: 1m 20s\tremaining: 18.9s\n",
            "810:\tlearn: 0.1782740\ttotal: 1m 20s\tremaining: 18.8s\n",
            "811:\tlearn: 0.1782501\ttotal: 1m 20s\tremaining: 18.7s\n",
            "812:\tlearn: 0.1782254\ttotal: 1m 20s\tremaining: 18.6s\n",
            "813:\tlearn: 0.1782016\ttotal: 1m 20s\tremaining: 18.5s\n",
            "814:\tlearn: 0.1781485\ttotal: 1m 20s\tremaining: 18.4s\n",
            "815:\tlearn: 0.1781294\ttotal: 1m 20s\tremaining: 18.3s\n",
            "816:\tlearn: 0.1781057\ttotal: 1m 21s\tremaining: 18.2s\n",
            "817:\tlearn: 0.1780477\ttotal: 1m 21s\tremaining: 18s\n",
            "818:\tlearn: 0.1780276\ttotal: 1m 21s\tremaining: 17.9s\n",
            "819:\tlearn: 0.1779918\ttotal: 1m 21s\tremaining: 17.8s\n",
            "820:\tlearn: 0.1779707\ttotal: 1m 21s\tremaining: 17.7s\n",
            "821:\tlearn: 0.1779578\ttotal: 1m 21s\tremaining: 17.6s\n",
            "822:\tlearn: 0.1779378\ttotal: 1m 21s\tremaining: 17.5s\n",
            "823:\tlearn: 0.1779165\ttotal: 1m 21s\tremaining: 17.4s\n",
            "824:\tlearn: 0.1778906\ttotal: 1m 21s\tremaining: 17.3s\n",
            "825:\tlearn: 0.1778802\ttotal: 1m 21s\tremaining: 17.2s\n",
            "826:\tlearn: 0.1778719\ttotal: 1m 21s\tremaining: 17.1s\n",
            "827:\tlearn: 0.1778468\ttotal: 1m 21s\tremaining: 17s\n",
            "828:\tlearn: 0.1778298\ttotal: 1m 21s\tremaining: 16.9s\n",
            "829:\tlearn: 0.1777857\ttotal: 1m 21s\tremaining: 16.7s\n",
            "830:\tlearn: 0.1777694\ttotal: 1m 21s\tremaining: 16.6s\n",
            "831:\tlearn: 0.1777558\ttotal: 1m 21s\tremaining: 16.5s\n",
            "832:\tlearn: 0.1777335\ttotal: 1m 21s\tremaining: 16.4s\n",
            "833:\tlearn: 0.1777204\ttotal: 1m 21s\tremaining: 16.3s\n",
            "834:\tlearn: 0.1777095\ttotal: 1m 22s\tremaining: 16.2s\n",
            "835:\tlearn: 0.1776800\ttotal: 1m 22s\tremaining: 16.1s\n",
            "836:\tlearn: 0.1776559\ttotal: 1m 22s\tremaining: 16s\n",
            "837:\tlearn: 0.1776251\ttotal: 1m 22s\tremaining: 15.9s\n",
            "838:\tlearn: 0.1776150\ttotal: 1m 22s\tremaining: 15.8s\n",
            "839:\tlearn: 0.1775994\ttotal: 1m 22s\tremaining: 15.7s\n",
            "840:\tlearn: 0.1775743\ttotal: 1m 22s\tremaining: 15.6s\n",
            "841:\tlearn: 0.1775545\ttotal: 1m 22s\tremaining: 15.5s\n",
            "842:\tlearn: 0.1775282\ttotal: 1m 22s\tremaining: 15.4s\n",
            "843:\tlearn: 0.1775132\ttotal: 1m 22s\tremaining: 15.3s\n",
            "844:\tlearn: 0.1774995\ttotal: 1m 22s\tremaining: 15.1s\n",
            "845:\tlearn: 0.1774873\ttotal: 1m 22s\tremaining: 15s\n",
            "846:\tlearn: 0.1774767\ttotal: 1m 22s\tremaining: 14.9s\n",
            "847:\tlearn: 0.1774554\ttotal: 1m 22s\tremaining: 14.8s\n",
            "848:\tlearn: 0.1774222\ttotal: 1m 22s\tremaining: 14.7s\n",
            "849:\tlearn: 0.1773963\ttotal: 1m 22s\tremaining: 14.6s\n",
            "850:\tlearn: 0.1773821\ttotal: 1m 22s\tremaining: 14.5s\n",
            "851:\tlearn: 0.1773579\ttotal: 1m 22s\tremaining: 14.4s\n",
            "852:\tlearn: 0.1773462\ttotal: 1m 23s\tremaining: 14.3s\n",
            "853:\tlearn: 0.1773089\ttotal: 1m 23s\tremaining: 14.2s\n",
            "854:\tlearn: 0.1772849\ttotal: 1m 23s\tremaining: 14.1s\n",
            "855:\tlearn: 0.1772609\ttotal: 1m 23s\tremaining: 14s\n",
            "856:\tlearn: 0.1772418\ttotal: 1m 23s\tremaining: 13.9s\n",
            "857:\tlearn: 0.1772144\ttotal: 1m 23s\tremaining: 13.8s\n",
            "858:\tlearn: 0.1771890\ttotal: 1m 23s\tremaining: 13.7s\n",
            "859:\tlearn: 0.1771758\ttotal: 1m 23s\tremaining: 13.6s\n",
            "860:\tlearn: 0.1771679\ttotal: 1m 23s\tremaining: 13.5s\n",
            "861:\tlearn: 0.1771517\ttotal: 1m 23s\tremaining: 13.4s\n",
            "862:\tlearn: 0.1771381\ttotal: 1m 23s\tremaining: 13.3s\n",
            "863:\tlearn: 0.1771197\ttotal: 1m 23s\tremaining: 13.2s\n",
            "864:\tlearn: 0.1770934\ttotal: 1m 23s\tremaining: 13.1s\n",
            "865:\tlearn: 0.1770673\ttotal: 1m 23s\tremaining: 13s\n",
            "866:\tlearn: 0.1770371\ttotal: 1m 23s\tremaining: 12.9s\n",
            "867:\tlearn: 0.1770028\ttotal: 1m 23s\tremaining: 12.8s\n",
            "868:\tlearn: 0.1769894\ttotal: 1m 23s\tremaining: 12.7s\n",
            "869:\tlearn: 0.1769826\ttotal: 1m 23s\tremaining: 12.5s\n",
            "870:\tlearn: 0.1769525\ttotal: 1m 24s\tremaining: 12.4s\n",
            "871:\tlearn: 0.1769316\ttotal: 1m 24s\tremaining: 12.3s\n",
            "872:\tlearn: 0.1769022\ttotal: 1m 24s\tremaining: 12.2s\n",
            "873:\tlearn: 0.1768894\ttotal: 1m 24s\tremaining: 12.1s\n",
            "874:\tlearn: 0.1768735\ttotal: 1m 24s\tremaining: 12s\n",
            "875:\tlearn: 0.1768602\ttotal: 1m 24s\tremaining: 11.9s\n",
            "876:\tlearn: 0.1768467\ttotal: 1m 24s\tremaining: 11.9s\n",
            "877:\tlearn: 0.1768237\ttotal: 1m 24s\tremaining: 11.8s\n",
            "878:\tlearn: 0.1767873\ttotal: 1m 24s\tremaining: 11.7s\n",
            "879:\tlearn: 0.1767706\ttotal: 1m 24s\tremaining: 11.6s\n",
            "880:\tlearn: 0.1767494\ttotal: 1m 25s\tremaining: 11.5s\n",
            "881:\tlearn: 0.1767348\ttotal: 1m 25s\tremaining: 11.4s\n",
            "882:\tlearn: 0.1767130\ttotal: 1m 25s\tremaining: 11.3s\n",
            "883:\tlearn: 0.1766790\ttotal: 1m 25s\tremaining: 11.2s\n",
            "884:\tlearn: 0.1766711\ttotal: 1m 25s\tremaining: 11.1s\n",
            "885:\tlearn: 0.1766586\ttotal: 1m 25s\tremaining: 11s\n",
            "886:\tlearn: 0.1766445\ttotal: 1m 25s\tremaining: 10.9s\n",
            "887:\tlearn: 0.1766273\ttotal: 1m 25s\tremaining: 10.8s\n",
            "888:\tlearn: 0.1766023\ttotal: 1m 26s\tremaining: 10.7s\n",
            "889:\tlearn: 0.1765730\ttotal: 1m 26s\tremaining: 10.7s\n",
            "890:\tlearn: 0.1765443\ttotal: 1m 26s\tremaining: 10.6s\n",
            "891:\tlearn: 0.1765316\ttotal: 1m 26s\tremaining: 10.5s\n",
            "892:\tlearn: 0.1765145\ttotal: 1m 26s\tremaining: 10.4s\n",
            "893:\tlearn: 0.1764997\ttotal: 1m 26s\tremaining: 10.3s\n",
            "894:\tlearn: 0.1764809\ttotal: 1m 26s\tremaining: 10.2s\n",
            "895:\tlearn: 0.1764674\ttotal: 1m 26s\tremaining: 10.1s\n",
            "896:\tlearn: 0.1764446\ttotal: 1m 27s\tremaining: 9.99s\n",
            "897:\tlearn: 0.1764267\ttotal: 1m 27s\tremaining: 9.9s\n",
            "898:\tlearn: 0.1764052\ttotal: 1m 27s\tremaining: 9.81s\n",
            "899:\tlearn: 0.1763884\ttotal: 1m 27s\tremaining: 9.72s\n",
            "900:\tlearn: 0.1763743\ttotal: 1m 27s\tremaining: 9.63s\n",
            "901:\tlearn: 0.1763561\ttotal: 1m 27s\tremaining: 9.53s\n",
            "902:\tlearn: 0.1763432\ttotal: 1m 27s\tremaining: 9.43s\n",
            "903:\tlearn: 0.1763150\ttotal: 1m 27s\tremaining: 9.33s\n",
            "904:\tlearn: 0.1762948\ttotal: 1m 27s\tremaining: 9.23s\n",
            "905:\tlearn: 0.1762864\ttotal: 1m 27s\tremaining: 9.13s\n",
            "906:\tlearn: 0.1762651\ttotal: 1m 28s\tremaining: 9.03s\n",
            "907:\tlearn: 0.1762522\ttotal: 1m 28s\tremaining: 8.93s\n",
            "908:\tlearn: 0.1762225\ttotal: 1m 28s\tremaining: 8.82s\n",
            "909:\tlearn: 0.1762018\ttotal: 1m 28s\tremaining: 8.72s\n",
            "910:\tlearn: 0.1761827\ttotal: 1m 28s\tremaining: 8.62s\n",
            "911:\tlearn: 0.1761636\ttotal: 1m 28s\tremaining: 8.52s\n",
            "912:\tlearn: 0.1761500\ttotal: 1m 28s\tremaining: 8.42s\n",
            "913:\tlearn: 0.1761258\ttotal: 1m 28s\tremaining: 8.33s\n",
            "914:\tlearn: 0.1760915\ttotal: 1m 28s\tremaining: 8.23s\n",
            "915:\tlearn: 0.1760722\ttotal: 1m 28s\tremaining: 8.14s\n",
            "916:\tlearn: 0.1760584\ttotal: 1m 28s\tremaining: 8.04s\n",
            "917:\tlearn: 0.1760451\ttotal: 1m 28s\tremaining: 7.95s\n",
            "918:\tlearn: 0.1760127\ttotal: 1m 29s\tremaining: 7.85s\n",
            "919:\tlearn: 0.1759715\ttotal: 1m 29s\tremaining: 7.76s\n",
            "920:\tlearn: 0.1759364\ttotal: 1m 29s\tremaining: 7.66s\n",
            "921:\tlearn: 0.1759123\ttotal: 1m 29s\tremaining: 7.57s\n",
            "922:\tlearn: 0.1758911\ttotal: 1m 29s\tremaining: 7.47s\n",
            "923:\tlearn: 0.1758727\ttotal: 1m 29s\tremaining: 7.38s\n",
            "924:\tlearn: 0.1758541\ttotal: 1m 29s\tremaining: 7.29s\n",
            "925:\tlearn: 0.1758258\ttotal: 1m 29s\tremaining: 7.19s\n",
            "926:\tlearn: 0.1758088\ttotal: 1m 30s\tremaining: 7.09s\n",
            "927:\tlearn: 0.1757953\ttotal: 1m 30s\tremaining: 7s\n",
            "928:\tlearn: 0.1757695\ttotal: 1m 30s\tremaining: 6.91s\n",
            "929:\tlearn: 0.1757469\ttotal: 1m 30s\tremaining: 6.81s\n",
            "930:\tlearn: 0.1757373\ttotal: 1m 30s\tremaining: 6.72s\n",
            "931:\tlearn: 0.1757182\ttotal: 1m 30s\tremaining: 6.62s\n",
            "932:\tlearn: 0.1757006\ttotal: 1m 30s\tremaining: 6.53s\n",
            "933:\tlearn: 0.1756881\ttotal: 1m 31s\tremaining: 6.43s\n",
            "934:\tlearn: 0.1756741\ttotal: 1m 31s\tremaining: 6.34s\n",
            "935:\tlearn: 0.1756465\ttotal: 1m 31s\tremaining: 6.24s\n",
            "936:\tlearn: 0.1756326\ttotal: 1m 31s\tremaining: 6.15s\n",
            "937:\tlearn: 0.1756180\ttotal: 1m 31s\tremaining: 6.05s\n",
            "938:\tlearn: 0.1756028\ttotal: 1m 31s\tremaining: 5.96s\n",
            "939:\tlearn: 0.1755896\ttotal: 1m 31s\tremaining: 5.86s\n",
            "940:\tlearn: 0.1755594\ttotal: 1m 32s\tremaining: 5.77s\n",
            "941:\tlearn: 0.1755392\ttotal: 1m 32s\tremaining: 5.67s\n",
            "942:\tlearn: 0.1755051\ttotal: 1m 32s\tremaining: 5.58s\n",
            "943:\tlearn: 0.1754746\ttotal: 1m 32s\tremaining: 5.48s\n",
            "944:\tlearn: 0.1754457\ttotal: 1m 32s\tremaining: 5.39s\n",
            "945:\tlearn: 0.1754229\ttotal: 1m 32s\tremaining: 5.29s\n",
            "946:\tlearn: 0.1754130\ttotal: 1m 32s\tremaining: 5.2s\n",
            "947:\tlearn: 0.1753859\ttotal: 1m 32s\tremaining: 5.1s\n",
            "948:\tlearn: 0.1753726\ttotal: 1m 33s\tremaining: 5s\n",
            "949:\tlearn: 0.1753432\ttotal: 1m 33s\tremaining: 4.91s\n",
            "950:\tlearn: 0.1753042\ttotal: 1m 33s\tremaining: 4.81s\n",
            "951:\tlearn: 0.1752936\ttotal: 1m 33s\tremaining: 4.71s\n",
            "952:\tlearn: 0.1752842\ttotal: 1m 33s\tremaining: 4.62s\n",
            "953:\tlearn: 0.1752555\ttotal: 1m 33s\tremaining: 4.52s\n",
            "954:\tlearn: 0.1752268\ttotal: 1m 33s\tremaining: 4.43s\n",
            "955:\tlearn: 0.1752069\ttotal: 1m 34s\tremaining: 4.33s\n",
            "956:\tlearn: 0.1751893\ttotal: 1m 34s\tremaining: 4.23s\n",
            "957:\tlearn: 0.1751739\ttotal: 1m 34s\tremaining: 4.14s\n",
            "958:\tlearn: 0.1751532\ttotal: 1m 34s\tremaining: 4.04s\n",
            "959:\tlearn: 0.1751297\ttotal: 1m 34s\tremaining: 3.94s\n",
            "960:\tlearn: 0.1751035\ttotal: 1m 34s\tremaining: 3.85s\n",
            "961:\tlearn: 0.1750708\ttotal: 1m 34s\tremaining: 3.75s\n",
            "962:\tlearn: 0.1750453\ttotal: 1m 35s\tremaining: 3.65s\n",
            "963:\tlearn: 0.1750125\ttotal: 1m 35s\tremaining: 3.55s\n",
            "964:\tlearn: 0.1749832\ttotal: 1m 35s\tremaining: 3.46s\n",
            "965:\tlearn: 0.1749574\ttotal: 1m 35s\tremaining: 3.36s\n",
            "966:\tlearn: 0.1749336\ttotal: 1m 35s\tremaining: 3.26s\n",
            "967:\tlearn: 0.1749145\ttotal: 1m 35s\tremaining: 3.17s\n",
            "968:\tlearn: 0.1748928\ttotal: 1m 35s\tremaining: 3.07s\n",
            "969:\tlearn: 0.1748718\ttotal: 1m 36s\tremaining: 2.97s\n",
            "970:\tlearn: 0.1748559\ttotal: 1m 36s\tremaining: 2.87s\n",
            "971:\tlearn: 0.1748416\ttotal: 1m 36s\tremaining: 2.77s\n",
            "972:\tlearn: 0.1748177\ttotal: 1m 36s\tremaining: 2.67s\n",
            "973:\tlearn: 0.1748056\ttotal: 1m 36s\tremaining: 2.58s\n",
            "974:\tlearn: 0.1747864\ttotal: 1m 36s\tremaining: 2.48s\n",
            "975:\tlearn: 0.1747617\ttotal: 1m 36s\tremaining: 2.38s\n",
            "976:\tlearn: 0.1747507\ttotal: 1m 36s\tremaining: 2.28s\n",
            "977:\tlearn: 0.1747256\ttotal: 1m 37s\tremaining: 2.18s\n",
            "978:\tlearn: 0.1747056\ttotal: 1m 37s\tremaining: 2.08s\n",
            "979:\tlearn: 0.1746845\ttotal: 1m 37s\tremaining: 1.99s\n",
            "980:\tlearn: 0.1746695\ttotal: 1m 37s\tremaining: 1.89s\n",
            "981:\tlearn: 0.1746498\ttotal: 1m 37s\tremaining: 1.79s\n",
            "982:\tlearn: 0.1746274\ttotal: 1m 37s\tremaining: 1.69s\n",
            "983:\tlearn: 0.1746038\ttotal: 1m 38s\tremaining: 1.59s\n",
            "984:\tlearn: 0.1745739\ttotal: 1m 38s\tremaining: 1.5s\n",
            "985:\tlearn: 0.1745557\ttotal: 1m 38s\tremaining: 1.4s\n",
            "986:\tlearn: 0.1745392\ttotal: 1m 38s\tremaining: 1.3s\n",
            "987:\tlearn: 0.1745191\ttotal: 1m 38s\tremaining: 1.2s\n",
            "988:\tlearn: 0.1745017\ttotal: 1m 38s\tremaining: 1.1s\n",
            "989:\tlearn: 0.1744829\ttotal: 1m 38s\tremaining: 999ms\n",
            "990:\tlearn: 0.1744654\ttotal: 1m 39s\tremaining: 900ms\n",
            "991:\tlearn: 0.1744447\ttotal: 1m 39s\tremaining: 800ms\n",
            "992:\tlearn: 0.1744266\ttotal: 1m 39s\tremaining: 700ms\n",
            "993:\tlearn: 0.1744062\ttotal: 1m 39s\tremaining: 600ms\n",
            "994:\tlearn: 0.1743872\ttotal: 1m 39s\tremaining: 500ms\n",
            "995:\tlearn: 0.1743635\ttotal: 1m 39s\tremaining: 400ms\n",
            "996:\tlearn: 0.1743552\ttotal: 1m 39s\tremaining: 300ms\n",
            "997:\tlearn: 0.1743384\ttotal: 1m 39s\tremaining: 200ms\n",
            "998:\tlearn: 0.1743216\ttotal: 1m 40s\tremaining: 100ms\n",
            "999:\tlearn: 0.1742957\ttotal: 1m 40s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9447079750963534"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using CatBoost Classifier for test data\n",
        "pred_prob_test_cat = np.array(model3.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_cat)"
      ],
      "metadata": {
        "id": "TM_djQsNFPRS",
        "outputId": "ae53c037-8aaa-46e1-cb85-09829b663797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.12692823e-01 8.85239051e-01 2.06812572e-03]\n",
            " [9.93739720e-01 5.46504020e-03 7.95240130e-04]\n",
            " [2.05738071e-01 1.11114329e-02 7.83150496e-01]\n",
            " ...\n",
            " [9.66987212e-01 2.04503061e-02 1.25624817e-02]\n",
            " [4.27445156e-03 9.95183795e-01 5.41752979e-04]\n",
            " [9.96438912e-01 1.21370761e-03 2.34738010e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GradientBoosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=100, max_features=2, random_state=0)\n",
        "gb_clf.fit(x_train_scaled,y_train)\n",
        "gb_clf.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "f_xxK-_jYhgh",
        "outputId": "05b70fab-2644-4fef-ac86-5b84143569d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9445597391046546"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using GradientBoosting Classifier for test data\n",
        "pred_prob_test_gb = np.array(gb_clf.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_gb)"
      ],
      "metadata": {
        "id": "LPc6n72JZQMK",
        "outputId": "b7152c4d-a459-476c-a3de-08a1d3e535f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.08405353 0.90290217 0.0130443 ]\n",
            " [0.98227451 0.01252745 0.00519804]\n",
            " [0.27665157 0.02962194 0.69372649]\n",
            " ...\n",
            " [0.96253862 0.02780198 0.0096594 ]\n",
            " [0.00923104 0.98836794 0.00240102]\n",
            " [0.98683235 0.00663547 0.00653218]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ExtraTrees Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "etf = ExtraTreesClassifier(n_estimators = 150, criterion = 'entropy')\n",
        "etf.fit(x_train_scaled,y_train)\n",
        "etf.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "RE71pozhF0aS",
        "outputId": "115d44ce-0722-4510-c4ee-a8e486d3bb36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9447820930922027"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using ExtraTrees Classifier for test data\n",
        "pred_prob_test_etf = np.array(etf.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_etf)"
      ],
      "metadata": {
        "id": "TNE-5iMMGM_q",
        "outputId": "c8f3e710-2111-4838-ce59-158a9a5c59c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.24       0.76       0.        ]\n",
            " [0.99333333 0.00666667 0.        ]\n",
            " [0.42       0.02       0.56      ]\n",
            " ...\n",
            " [0.95333333 0.02666667 0.02      ]\n",
            " [0.00666667 0.99333333 0.        ]\n",
            " [0.98       0.00666667 0.01333333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing Snapshot ensemble\n",
        "from keras.callbacks import Callback\n",
        "from keras import backend\n",
        "from keras.models import load_model\n",
        "from numpy import pi\n",
        "import math\n",
        "\n",
        "class SnapshotEnsemble(Callback):\n",
        "\n",
        "    __snapshot_name_fmt = \"snapshot_%d.hdf5\"\n",
        "\n",
        "    def __init__(self, n_models, n_epochs_per_model, lr_max, verbose=1):\n",
        "\n",
        "        # n_models: number of snapshots\n",
        "        # n_epochs_per_model: epochs per snapshot\n",
        "        # lr_max: maximum learning rate\n",
        "\n",
        "        self.n_epochs_per_model = n_epochs_per_model\n",
        "        self.n_models = n_models\n",
        "        self.n_epochs_total = self.n_models * self.n_epochs_per_model\n",
        "        self.lr_max = lr_max\n",
        "        self.verbose = verbose\n",
        "        self.lrs = []\n",
        "\n",
        "    def cosine_annealing(self, epoch):\n",
        "        cos_inner = (math.pi * (epoch % self.n_epochs_per_model)) / self.n_epochs_per_model\n",
        "        return self.lr_max / 2 * (math.cos(cos_inner) + 1)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        lr = self.cosine_annealing(epoch)\n",
        "        backend.set_value(self.model.optimizer.lr, lr)\n",
        "        self.lrs.append(lr)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (epoch + 1) % self.n_epochs_per_model == 0:\n",
        "            filename = self.__snapshot_name_fmt % ((epoch + 1) // self.n_epochs_per_model)\n",
        "            self.model.save(filename)\n",
        "            if self.verbose:\n",
        "                print('Epoch %d: snapshot saved to %s' % (epoch, filename))\n",
        "\n",
        "    def load_ensemble(self):\n",
        "        models = []\n",
        "        for i in range(self.n_models):\n",
        "            models.append(load_model(self.__snapshot_name_fmt % (i + 1)))\n",
        "        return models"
      ],
      "metadata": {
        "id": "xDKSa4s5zEXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Snapshot_Ensemble_callback = SnapshotEnsemble(n_models=3, n_epochs_per_model=20, lr_max=0.01)"
      ],
      "metadata": {
        "id": "hr4h9z6FzIag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDUg3tkkTqFw",
        "outputId": "c835b642-62e3-4ffb-927d-a296181d4ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "3795/3795 [==============================] - 18s 4ms/step - loss: 0.3010 - accuracy: 0.9094 - val_loss: 0.2687 - val_accuracy: 0.9330\n",
            "Epoch 2/60\n",
            "3795/3795 [==============================] - 19s 5ms/step - loss: 0.2585 - accuracy: 0.9268 - val_loss: 0.2734 - val_accuracy: 0.9240\n",
            "Epoch 3/60\n",
            "3795/3795 [==============================] - 29s 8ms/step - loss: 0.2557 - accuracy: 0.9284 - val_loss: 0.2637 - val_accuracy: 0.9224\n",
            "Epoch 4/60\n",
            "3795/3795 [==============================] - 23s 6ms/step - loss: 0.2486 - accuracy: 0.9301 - val_loss: 0.2739 - val_accuracy: 0.9274\n",
            "Epoch 5/60\n",
            "3795/3795 [==============================] - 26s 7ms/step - loss: 0.2494 - accuracy: 0.9297 - val_loss: 0.2559 - val_accuracy: 0.9206\n",
            "Epoch 6/60\n",
            "3795/3795 [==============================] - 20s 5ms/step - loss: 0.2457 - accuracy: 0.9309 - val_loss: 0.2471 - val_accuracy: 0.9298\n",
            "Epoch 7/60\n",
            "3795/3795 [==============================] - 23s 6ms/step - loss: 0.2440 - accuracy: 0.9324 - val_loss: 0.2454 - val_accuracy: 0.9303\n",
            "Epoch 8/60\n",
            "3795/3795 [==============================] - 30s 8ms/step - loss: 0.2413 - accuracy: 0.9333 - val_loss: 0.2388 - val_accuracy: 0.9349\n",
            "Epoch 9/60\n",
            "3795/3795 [==============================] - 21s 6ms/step - loss: 0.2363 - accuracy: 0.9352 - val_loss: 0.2326 - val_accuracy: 0.9352\n",
            "Epoch 10/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2340 - accuracy: 0.9356 - val_loss: 0.2363 - val_accuracy: 0.9353\n",
            "Epoch 11/60\n",
            "3795/3795 [==============================] - 25s 7ms/step - loss: 0.2323 - accuracy: 0.9362 - val_loss: 0.2404 - val_accuracy: 0.9360\n",
            "Epoch 12/60\n",
            "3795/3795 [==============================] - 29s 8ms/step - loss: 0.2276 - accuracy: 0.9374 - val_loss: 0.2383 - val_accuracy: 0.9351\n",
            "Epoch 13/60\n",
            "3795/3795 [==============================] - 30s 8ms/step - loss: 0.2258 - accuracy: 0.9385 - val_loss: 0.2516 - val_accuracy: 0.9311\n",
            "Epoch 14/60\n",
            "3795/3795 [==============================] - 20s 5ms/step - loss: 0.2223 - accuracy: 0.9391 - val_loss: 0.2518 - val_accuracy: 0.9375\n",
            "Epoch 15/60\n",
            "3795/3795 [==============================] - 21s 5ms/step - loss: 0.2212 - accuracy: 0.9389 - val_loss: 0.2270 - val_accuracy: 0.9369\n",
            "Epoch 16/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2199 - accuracy: 0.9394 - val_loss: 0.2258 - val_accuracy: 0.9375\n",
            "Epoch 17/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2181 - accuracy: 0.9404 - val_loss: 0.2301 - val_accuracy: 0.9371\n",
            "Epoch 18/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2174 - accuracy: 0.9403 - val_loss: 0.2335 - val_accuracy: 0.9375\n",
            "Epoch 19/60\n",
            "3795/3795 [==============================] - 17s 5ms/step - loss: 0.2165 - accuracy: 0.9404 - val_loss: 0.2255 - val_accuracy: 0.9380\n",
            "Epoch 20/60\n",
            "3788/3795 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9411Epoch 19: snapshot saved to snapshot_1.hdf5\n",
            "3795/3795 [==============================] - 19s 5ms/step - loss: 0.2163 - accuracy: 0.9411 - val_loss: 0.2238 - val_accuracy: 0.9386\n",
            "Epoch 21/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2460 - accuracy: 0.9315 - val_loss: 0.2301 - val_accuracy: 0.9380\n",
            "Epoch 22/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2451 - accuracy: 0.9316 - val_loss: 0.2443 - val_accuracy: 0.9338\n",
            "Epoch 23/60\n",
            "3795/3795 [==============================] - 15s 4ms/step - loss: 0.2420 - accuracy: 0.9323 - val_loss: 0.2404 - val_accuracy: 0.9349\n",
            "Epoch 24/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2434 - accuracy: 0.9332 - val_loss: 0.2547 - val_accuracy: 0.9306\n",
            "Epoch 25/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2389 - accuracy: 0.9350 - val_loss: 0.2384 - val_accuracy: 0.9351\n",
            "Epoch 26/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2384 - accuracy: 0.9343 - val_loss: 0.3385 - val_accuracy: 0.8877\n",
            "Epoch 27/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2387 - accuracy: 0.9345 - val_loss: 0.2366 - val_accuracy: 0.9322\n",
            "Epoch 28/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2349 - accuracy: 0.9354 - val_loss: 0.2393 - val_accuracy: 0.9349\n",
            "Epoch 29/60\n",
            "3795/3795 [==============================] - 15s 4ms/step - loss: 0.2368 - accuracy: 0.9371 - val_loss: 0.2438 - val_accuracy: 0.9337\n",
            "Epoch 30/60\n",
            "3795/3795 [==============================] - 15s 4ms/step - loss: 0.2327 - accuracy: 0.9370 - val_loss: 0.2364 - val_accuracy: 0.9373\n",
            "Epoch 31/60\n",
            "3795/3795 [==============================] - 15s 4ms/step - loss: 0.2299 - accuracy: 0.9370 - val_loss: 0.2300 - val_accuracy: 0.9380\n",
            "Epoch 32/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2292 - accuracy: 0.9374 - val_loss: 0.2418 - val_accuracy: 0.9350\n",
            "Epoch 33/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2257 - accuracy: 0.9383 - val_loss: 0.2306 - val_accuracy: 0.9370\n",
            "Epoch 34/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2236 - accuracy: 0.9389 - val_loss: 0.2292 - val_accuracy: 0.9351\n",
            "Epoch 35/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2215 - accuracy: 0.9394 - val_loss: 0.2286 - val_accuracy: 0.9380\n",
            "Epoch 36/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2199 - accuracy: 0.9398 - val_loss: 0.2278 - val_accuracy: 0.9362\n",
            "Epoch 37/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2187 - accuracy: 0.9406 - val_loss: 0.2269 - val_accuracy: 0.9380\n",
            "Epoch 38/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2175 - accuracy: 0.9407 - val_loss: 0.2256 - val_accuracy: 0.9379\n",
            "Epoch 39/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2170 - accuracy: 0.9412 - val_loss: 0.2251 - val_accuracy: 0.9381\n",
            "Epoch 40/60\n",
            "3789/3795 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9410Epoch 39: snapshot saved to snapshot_2.hdf5\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2167 - accuracy: 0.9410 - val_loss: 0.2254 - val_accuracy: 0.9384\n",
            "Epoch 41/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2437 - accuracy: 0.9336 - val_loss: 0.2342 - val_accuracy: 0.9380\n",
            "Epoch 42/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2397 - accuracy: 0.9343 - val_loss: 0.2453 - val_accuracy: 0.9351\n",
            "Epoch 43/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2425 - accuracy: 0.9330 - val_loss: 0.2518 - val_accuracy: 0.9329\n",
            "Epoch 44/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2440 - accuracy: 0.9337 - val_loss: 0.2548 - val_accuracy: 0.9337\n",
            "Epoch 45/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2396 - accuracy: 0.9348 - val_loss: 0.2331 - val_accuracy: 0.9366\n",
            "Epoch 46/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2387 - accuracy: 0.9347 - val_loss: 0.2595 - val_accuracy: 0.9251\n",
            "Epoch 47/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2361 - accuracy: 0.9357 - val_loss: 0.2353 - val_accuracy: 0.9359\n",
            "Epoch 48/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2345 - accuracy: 0.9348 - val_loss: 0.2391 - val_accuracy: 0.9340\n",
            "Epoch 49/60\n",
            "3795/3795 [==============================] - 19s 5ms/step - loss: 0.2337 - accuracy: 0.9365 - val_loss: 0.2369 - val_accuracy: 0.9291\n",
            "Epoch 50/60\n",
            "3795/3795 [==============================] - 23s 6ms/step - loss: 0.2337 - accuracy: 0.9359 - val_loss: 0.2325 - val_accuracy: 0.9355\n",
            "Epoch 51/60\n",
            "3795/3795 [==============================] - 20s 5ms/step - loss: 0.2271 - accuracy: 0.9379 - val_loss: 0.2269 - val_accuracy: 0.9364\n",
            "Epoch 52/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2248 - accuracy: 0.9388 - val_loss: 0.2338 - val_accuracy: 0.9354\n",
            "Epoch 53/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2237 - accuracy: 0.9389 - val_loss: 0.2273 - val_accuracy: 0.9382\n",
            "Epoch 54/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2226 - accuracy: 0.9396 - val_loss: 0.2282 - val_accuracy: 0.9375\n",
            "Epoch 55/60\n",
            "3795/3795 [==============================] - 26s 7ms/step - loss: 0.2204 - accuracy: 0.9402 - val_loss: 0.2284 - val_accuracy: 0.9383\n",
            "Epoch 56/60\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2193 - accuracy: 0.9408 - val_loss: 0.2259 - val_accuracy: 0.9377\n",
            "Epoch 57/60\n",
            "3795/3795 [==============================] - 17s 5ms/step - loss: 0.2182 - accuracy: 0.9409 - val_loss: 0.2254 - val_accuracy: 0.9383\n",
            "Epoch 58/60\n",
            "3795/3795 [==============================] - 16s 4ms/step - loss: 0.2172 - accuracy: 0.9407 - val_loss: 0.2250 - val_accuracy: 0.9380\n",
            "Epoch 59/60\n",
            "3795/3795 [==============================] - 17s 4ms/step - loss: 0.2167 - accuracy: 0.9413 - val_loss: 0.2248 - val_accuracy: 0.9380\n",
            "Epoch 60/60\n",
            "3789/3795 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9412Epoch 59: snapshot saved to snapshot_3.hdf5\n",
            "3795/3795 [==============================] - 18s 5ms/step - loss: 0.2168 - accuracy: 0.9412 - val_loss: 0.2246 - val_accuracy: 0.9383\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64658ad290>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#ANN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model_ann = keras.Sequential([\n",
        "    keras.layers.Dense(7, input_shape=(7,), activation='relu'),\n",
        "    keras.layers.Dense(15, activation='relu'),\n",
        "    keras.layers.Dense(80, activation='relu'),\n",
        "    keras.layers.Dense(200, activation='relu'),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(40, activation='relu'),\n",
        "    keras.layers.Dense(20, activation='relu'),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_ann.compile(optimizer='adam',\n",
        "              loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_ann.fit(x_train_scaled, y_train, validation_data=(x_val_scaled, y_val), callbacks = [Snapshot_Ensemble_callback], epochs = Snapshot_Ensemble_callback.n_epochs_total)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtaining individual model accuracy\n",
        "models = Snapshot_Ensemble_callback.load_ensemble()\n",
        "for model in models:\n",
        "    model.evaluate(x_val_scaled, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhDJ95yiAsL7",
        "outputId": "2b8d2165-7774-4a53-cfc1-c1128caa6217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422/422 [==============================] - 4s 6ms/step - loss: 0.2238 - accuracy: 0.9386\n",
            "422/422 [==============================] - 3s 5ms/step - loss: 0.2254 - accuracy: 0.9384\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.2246 - accuracy: 0.9383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Snapshot Ensemble of the models\n",
        "weights = [0.92, 0.93, 0.94]\n",
        "predictions = []\n",
        "val_final = np.zeros([len(x_val_scaled), 3])\n",
        "final = np.zeros([len(x_test_scaled), 3])\n",
        "for i, model in enumerate(models):\n",
        "    val_pred = np.array(model.predict(x_val_scaled))\n",
        "    pred = np.array(model.predict(x_test_scaled))\n",
        "    val_final = val_final + weights[i] * val_pred\n",
        "    final = final + weights[i] * pred\n",
        "for i in range(len(x_val_scaled)):\n",
        "    predictions.append(np.argmax(val_final[i]))\n",
        "c = 0\n",
        "y_val = np.array(y_val)\n",
        "for i in range(len(x_val_scaled)):\n",
        "    if predictions[i] == y_val[i]:\n",
        "        c+=1;\n",
        "print(\"Ensemble accuracy: \", c/len(x_val_scaled))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAmGSGnf1EJ0",
        "outputId": "d4369c50-d9f4-474d-c9ab-3ef8ed786a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "422/422 [==============================] - 1s 2ms/step\n",
            "2811/2811 [==============================] - 6s 2ms/step\n",
            "422/422 [==============================] - 1s 2ms/step\n",
            "2811/2811 [==============================] - 5s 2ms/step\n",
            "422/422 [==============================] - 1s 2ms/step\n",
            "2811/2811 [==============================] - 7s 3ms/step\n",
            "Ensemble accuracy:  0.9385561814408538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fItC_idrdAdG",
        "outputId": "ccd623d9-5667-4f54-d565-a5afb290c157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2811/2811 [==============================] - 5s 2ms/step\n",
            "[[6.2942110e-02 9.3620700e-01 8.5094135e-04]\n",
            " [9.8847586e-01 1.0635775e-02 8.8825234e-04]\n",
            " [3.1274137e-01 7.7202404e-03 6.7953837e-01]\n",
            " ...\n",
            " [9.5337498e-01 4.2527270e-02 4.0977774e-03]\n",
            " [2.1943133e-02 9.7703892e-01 1.0179415e-03]\n",
            " [9.8134065e-01 1.0600814e-02 8.0584576e-03]]\n"
          ]
        }
      ],
      "source": [
        "#Storing the predicted probabilities obtained using ANN for test data\n",
        "pred_prob_test_ann = model_ann.predict(x_test_scaled)\n",
        "print(pred_prob_test_ann)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling with experimental weights\n",
        "pred_ensem_test_final = (3*pred_prob_test_lgbm + 2*pred_prob_test_rf + 5*pred_prob_test_cat + pred_prob_test_etf + 4*pred_prob_test_gb + pred_prob_test_ann)\n",
        "print(pred_ensem_test_final)"
      ],
      "metadata": {
        "id": "hswWxYkwET5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910186f6-3666-4387-b037-9e2ae9bbd1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.11902442 0.87688429 0.00409129]\n",
            " [0.98706754 0.0109525  0.00197996]\n",
            " [0.23926786 0.01972724 0.74100491]\n",
            " ...\n",
            " [0.96597891 0.02398768 0.0100334 ]\n",
            " [0.00578804 0.99291754 0.00129442]\n",
            " [0.98384252 0.00434653 0.01181095]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ensem_test = []\n",
        "for i in pred_ensem_test_final:\n",
        "  pred_ensem_test.append(np.argmax(i)+1)\n",
        "pred_ensem_test = np.array(pred_ensem_test)\n",
        "print(pred_ensem_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siDyhfJEJq6t",
        "outputId": "c880134a-6ed0-4ed0-d700-642848a12717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 3 ... 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm_RfZDfKETw"
      },
      "outputs": [],
      "source": [
        "#Converting to dataframe\n",
        "dfx = pd.DataFrame(list(zip(pred_ensem_test)),\n",
        "               columns = ['stellar'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfx.insert(loc = 0,\n",
        "          column = 'id',\n",
        "          value = df_test['id'])"
      ],
      "metadata": {
        "id": "tfN49ps1asgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZA9CtwEKETx"
      },
      "outputs": [],
      "source": [
        "dfx.to_csv('SOS_ensemble_final.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}